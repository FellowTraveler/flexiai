{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /home/razvansavin/Proiecte/flexiai/examples/Code examples\n",
      "Changed Directory to: /home/razvansavin/Proiecte/flexiai\n",
      "Project root added to sys.path\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Check current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Current Directory: {current_dir}\")\n",
    "\n",
    "# Change to your project root directory\n",
    "project_root = '/home/razvansavin/Proiecte/flexiai'\n",
    "os.chdir(project_root)\n",
    "print(f\"Changed Directory to: {os.getcwd()}\")\n",
    "\n",
    "# Add project root directory to sys.path\n",
    "sys.path.append(project_root)\n",
    "print(f\"Project root added to sys.path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'openai.OpenAI'>\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'add_messages_dynamically', 'add_user_message', 'assistant_function_mapping', 'assistant_transformer', 'attach_assistant_to_thread', 'call_parallel_functions', 'change_thread_status', 'check_for_thread_and_status', 'clear_all_sessions', 'client', 'continue_conversation_with_assistant', 'create_advanced_run', 'create_and_monitor_run', 'create_run', 'create_session', 'create_thread', 'create_vector_store', 'credential_manager', 'delete_session', 'delete_thread', 'delete_vector_store', 'execute_task', 'get_all_sessions', 'get_session', 'handle_requires_action', 'initialize_agent', 'list_files_in_vector_store', 'list_vector_stores', 'load_processed_content', 'logger', 'message_manager', 'multi_agent_system', 'parallel_tool_calls', 'personal_function_mapping', 'process_and_print_messages', 'retrieve_file_batch_details', 'retrieve_message_object', 'retrieve_messages', 'retrieve_messages_dynamically', 'retrieve_thread', 'retrieve_vector_store_details', 'run_manager', 'save_processed_content', 'search_files_in_vector_store', 'session_manager', 'task_manager', 'thread_initialization', 'thread_manager', 'update_assistant_in_thread', 'update_assistant_with_vector_store', 'update_thread', 'upload_files_and_poll', 'vector_store_manager', 'wait_for_run_completion']\n",
      "Help on FlexiAI in module flexiai.core.flexiai_client object:\n",
      "\n",
      "class FlexiAI(builtins.object)\n",
      " |  FlexiAI class is the central hub for managing different AI-related operations such as thread management,\n",
      " |  message management, run management, session management, and vector store management.\n",
      " |  \n",
      " |  This class initializes various managers and loads user-defined tasks to facilitate the interactions with\n",
      " |  AI assistants.\n",
      " |  \n",
      " |  Link: https://github.com/SavinRazvan/flexiai/blob/main/flexiai/core/flexiai_client.py\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self)\n",
      " |      Initializes the FlexiAI class.\n",
      " |      \n",
      " |      Sets up logging, initializes the CredentialManager to handle credentials, and initializes various managers\n",
      " |      including TaskManager, ThreadManager, MessageManager, RunManager, MultiAgentSystemManager, SessionManager,\n",
      " |      and VectorStoreManager.\n",
      " |      \n",
      " |      The function mappings are updated after loading user tasks to ensure that all user-defined tasks are properly\n",
      " |      registered.\n",
      " |      \n",
      " |      Attributes:\n",
      " |          logger (logging.Logger): Logger for logging information, warnings, and errors.\n",
      " |          credential_manager (CredentialManager): Manager for handling credentials.\n",
      " |          client (object): Client object initialized by the CredentialManager.\n",
      " |          task_manager (TaskManager): Manager for handling tasks.\n",
      " |          thread_manager (ThreadManager): Manager for handling threads.\n",
      " |          message_manager (MessageManager): Manager for handling messages.\n",
      " |          run_manager (RunManager): Manager for handling runs.\n",
      " |          multi_agent_system (MultiAgentSystemManager): Manager for handling multi-agent systems.\n",
      " |          session_manager (SessionManager): Manager for handling sessions.\n",
      " |          vector_store_manager (VectorStoreManager): Manager for handling vector stores.\n",
      " |          personal_function_mapping (dict): Mapping of personal functions loaded from user tasks.\n",
      " |          assistant_function_mapping (dict): Mapping of assistant functions loaded from user tasks.\n",
      " |  \n",
      " |  add_messages_dynamically(self, thread_id, messages, role=None, metadata=None)\n",
      " |      Adds multiple user messages to a specified thread dynamically with optional metadata.\n",
      " |      \n",
      " |      Args:\n",
      " |          thread_id (str): The ID of the thread.\n",
      " |          messages (list): A list of dictionaries containing the message content and optional metadata. \n",
      " |                          Each dictionary should have the following structure:\n",
      " |                          {\n",
      " |                              \"content\": \"Message content\",\n",
      " |                              \"metadata\": {\"key\": \"value\"} (optional)\n",
      " |                          }\n",
      " |          role (str, optional): The role of the message sender. Defaults to None.\n",
      " |          metadata (dict, optional): Default metadata to include with each message if not provided in individual messages.\n",
      " |      \n",
      " |      Returns:\n",
      " |          list: A list of message objects that were added to the thread.\n",
      " |      \n",
      " |      Raises:\n",
      " |          OpenAIError: If the API call to add a message fails.\n",
      " |          Exception: If an unexpected error occurs.\n",
      " |  \n",
      " |  add_user_message(self, thread_id, user_message)\n",
      " |      Adds a user message to a specified thread using the MessageManager.\n",
      " |      \n",
      " |      Args:\n",
      " |          thread_id (str): The ID of the thread.\n",
      " |          user_message (str): The content of the user's message.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: The message object that was added to the thread.\n",
      " |  \n",
      " |  assistant_transformer(self, thread_id, new_assistant_id)\n",
      " |      Attaches a new assistant to an existing thread and runs the thread to speak with the new assistant using the RunManager.\n",
      " |      \n",
      " |      Args:\n",
      " |          thread_id (str): The ID of the existing thread.\n",
      " |          new_assistant_id (str): The ID of the new assistant to attach.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: The final run object indicating the result of the interaction.\n",
      " |  \n",
      " |  attach_assistant_to_thread(self, assistant_id, thread_id)\n",
      " |      Attaches an assistant to an existing thread using the ThreadManager.\n",
      " |      \n",
      " |      Args:\n",
      " |          assistant_id (str): The ID of the assistant.\n",
      " |          thread_id (str): The ID of the thread.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: The run object indicating the assistant has been attached.\n",
      " |  \n",
      " |  call_parallel_functions(self, tasks)\n",
      " |      Wrapper to run parallel tool calls in an asynchronous event loop.\n",
      " |      \n",
      " |      Args:\n",
      " |          tasks (list): A list of dictionaries where each dictionary contains:\n",
      " |              - function_name (str): The name of the function to call.\n",
      " |              - parameters (dict): The parameters to pass to the function.\n",
      " |      \n",
      " |      Returns:\n",
      " |          list: A list of results from each function call.\n",
      " |  \n",
      " |  change_thread_status(self, assistant_id, new_status)\n",
      " |      Updates the status of a thread identified by the assistant ID.\n",
      " |      \n",
      " |      Args:\n",
      " |          assistant_id (str): The unique identifier for the assistant.\n",
      " |          new_status (str): The new status to set for the thread.\n",
      " |  \n",
      " |  check_for_thread_and_status(self, assistant_id)\n",
      " |      Checks if there is an existing thread for the given assistant ID and retrieves its status.\n",
      " |      \n",
      " |      Args:\n",
      " |          assistant_id (str): The unique identifier for the assistant.\n",
      " |      \n",
      " |      Returns:\n",
      " |          tuple: A tuple of (thread_id, status) if the thread exists, otherwise (None, None).\n",
      " |  \n",
      " |  clear_all_sessions(self)\n",
      " |      Clears all current sessions.\n",
      " |      \n",
      " |      Returns:\n",
      " |          bool: True if all sessions were cleared successfully, False otherwise.\n",
      " |  \n",
      " |  continue_conversation_with_assistant(self, assistant_id, user_content)\n",
      " |      Continues the conversation with an assistant by submitting user content and managing the resulting run.\n",
      " |      \n",
      " |      Args:\n",
      " |          assistant_id (str): The unique identifier for the assistant.\n",
      " |          user_content (str): The content submitted by the user.\n",
      " |      \n",
      " |      Returns:\n",
      " |          str: A message indicating the result of the conversation continuation.\n",
      " |  \n",
      " |  create_advanced_run(self, assistant_id, thread_id, user_message)\n",
      " |      Creates an advanced run with a user message for a specified assistant and thread using the RunManager.\n",
      " |      \n",
      " |      Args:\n",
      " |          assistant_id (str): The ID of the assistant.\n",
      " |          thread_id (str): The ID of the thread.\n",
      " |          user_message (str): The user's message content.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: The run object if successful, None otherwise.\n",
      " |  \n",
      " |  create_and_monitor_run(self, assistant_id, thread_id, user_message=None, role=None, metadata=None)\n",
      " |      Creates and runs a thread with the specified assistant, optionally adding a user message,\n",
      " |      and monitors its status until completion or failure using the RunManager.\n",
      " |      \n",
      " |      Args:\n",
      " |          assistant_id (str): The ID of the assistant.\n",
      " |          thread_id (str): The ID of the thread.\n",
      " |          user_message (str, optional): The user's message content to add before creating the run.\n",
      " |          role (str, optional): The role of the message sender. Defaults to 'user'.\n",
      " |          metadata (dict, optional): Metadata to include with the message.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None\n",
      " |  \n",
      " |  create_run(self, assistant_id, thread_id)\n",
      " |      Creates a new run for a specified assistant and thread using the RunManager.\n",
      " |      \n",
      " |      Args:\n",
      " |          assistant_id (str): The ID of the assistant.\n",
      " |          thread_id (str): The ID of the thread.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: The run object if successful, None otherwise.\n",
      " |  \n",
      " |  create_session(self, session_id, data)\n",
      " |      Creates a new session or updates an existing session with the given session_id.\n",
      " |      \n",
      " |      Args:\n",
      " |          session_id (str): The ID of the session.\n",
      " |          data (dict): The data to store in the session.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict: The session data.\n",
      " |  \n",
      " |  create_thread(self)\n",
      " |      Creates a new thread.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: The thread object.\n",
      " |      \n",
      " |      Raises:\n",
      " |          OpenAIError: If the API call to create a new thread fails.\n",
      " |          Exception: If an unexpected error occurs.\n",
      " |  \n",
      " |  create_vector_store(self, name)\n",
      " |      Creates a new vector store with a specified name using the VectorStoreManager.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): The name of the vector store.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: The newly created vector store object.\n",
      " |  \n",
      " |  delete_session(self, session_id)\n",
      " |      Deletes session data by session_id.\n",
      " |      \n",
      " |      Args:\n",
      " |          session_id (str): The ID of the session to delete.\n",
      " |      \n",
      " |      Returns:\n",
      " |          bool: True if the session was deleted successfully, False otherwise.\n",
      " |  \n",
      " |  delete_thread(self, thread_id)\n",
      " |      Deletes a thread by its ID using the ThreadManager.\n",
      " |      \n",
      " |      Args:\n",
      " |          thread_id (str): The ID of the thread to delete.\n",
      " |      \n",
      " |      Returns:\n",
      " |          bool: True if the thread was deleted successfully, False otherwise.\n",
      " |  \n",
      " |  delete_vector_store(self, vector_store_id)\n",
      " |      Deletes a vector store using the VectorStoreManager.\n",
      " |      \n",
      " |      Args:\n",
      " |          vector_store_id (str): The ID of the vector store.\n",
      " |      \n",
      " |      Returns:\n",
      " |          bool: True if the vector store was deleted successfully, False otherwise.\n",
      " |  \n",
      " |  execute_task(self, function_name, parameters)\n",
      " |      Executes a task for a given function name and parameters.\n",
      " |      \n",
      " |      Args:\n",
      " |          function_name (str): The name of the function to execute.\n",
      " |          parameters (dict): The parameters to pass to the function.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: The result of the function execution.\n",
      " |  \n",
      " |  get_all_sessions(self)\n",
      " |      Retrieves all current sessions.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict: A dictionary containing all current sessions.\n",
      " |  \n",
      " |  get_session(self, session_id)\n",
      " |      Retrieves session data by session_id.\n",
      " |      \n",
      " |      Args:\n",
      " |          session_id (str): The ID of the session.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict: The session data.\n",
      " |  \n",
      " |  handle_requires_action(self, run, assistant_id, thread_id)\n",
      " |      Handles the required actions for a given run by executing the necessary tool functions either in parallel or sequentially.\n",
      " |      \n",
      " |      Args:\n",
      " |          run (object): The run object containing the required action.\n",
      " |          assistant_id (str): The ID of the assistant handling the action.\n",
      " |          thread_id (str): The ID of the thread in which the action is being handled.\n",
      " |  \n",
      " |  initialize_agent(self, assistant_id)\n",
      " |      Initializes an agent for the given assistant ID. If a thread already exists for the assistant ID,\n",
      " |      it returns a message indicating the existing thread. Otherwise, it creates a new thread and returns\n",
      " |      a message indicating successful initialization.\n",
      " |      \n",
      " |      Args:\n",
      " |          assistant_id (str): The unique identifier for the assistant.\n",
      " |      \n",
      " |      Returns:\n",
      " |          str: A message indicating the result of the initialization.\n",
      " |  \n",
      " |  list_files_in_vector_store(self, vector_store_id, batch_id)\n",
      " |      Lists all files that have been uploaded to a specific vector store using the VectorStoreManager.\n",
      " |      \n",
      " |      Args:\n",
      " |          vector_store_id (str): The ID of the vector store.\n",
      " |          batch_id (str): The ID of the file batch.\n",
      " |      \n",
      " |      Returns:\n",
      " |          list: A list of files in the vector store.\n",
      " |  \n",
      " |  list_vector_stores(self)\n",
      " |      Retrieves a list of all existing vector stores using the VectorStoreManager.\n",
      " |      \n",
      " |      Returns:\n",
      " |          list: A list of vector store objects.\n",
      " |  \n",
      " |  load_processed_content(self, from_assistant_id, to_assistant_id, multiple_retrieval=False)\n",
      " |      Loads the stored processed user content using the from_assistant_id and to_assistant_id.\n",
      " |      Optionally retrieves content from all assistants if multiple_retrieval is True.\n",
      " |      \n",
      " |      Args:\n",
      " |          from_assistant_id (str): The assistant identifier from which the content originates.\n",
      " |          to_assistant_id (str): The assistant identifier to which the content is directed.\n",
      " |          multiple_retrieval (bool, optional): Whether to retrieve content from all sources, not just the specified to_assistant_id. Defaults to False.\n",
      " |      \n",
      " |      Returns:\n",
      " |          list: A list of stored user content if found, otherwise an empty list.\n",
      " |  \n",
      " |  parallel_tool_calls(self, tasks)\n",
      " |      Executes tool calls in parallel.\n",
      " |      \n",
      " |      Args:\n",
      " |          tasks (list): A list of task dictionaries containing function names and parameters.\n",
      " |      \n",
      " |      Returns:\n",
      " |          list: A list of results from the parallel execution of tool calls.\n",
      " |  \n",
      " |  process_and_print_messages(self, messages)\n",
      " |      Processes and prints the role and content of each message using the MessageManager.\n",
      " |      \n",
      " |      Args:\n",
      " |          messages (list): The list of message objects.\n",
      " |  \n",
      " |  retrieve_file_batch_details(self, vector_store_id, batch_id)\n",
      " |      Retrieves the status and details of a specific file batch within a vector store using the VectorStoreManager.\n",
      " |      \n",
      " |      Args:\n",
      " |          vector_store_id (str): The ID of the vector store.\n",
      " |          batch_id (str): The ID of the file batch.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: The file batch object with detailed information.\n",
      " |  \n",
      " |  retrieve_message_object(self, thread_id, order='asc', limit=20)\n",
      " |      Retrieves message objects from a specified thread using the MessageManager.\n",
      " |      \n",
      " |      Args:\n",
      " |          thread_id (str): The ID of the thread.\n",
      " |          order (str, optional): The order in which to retrieve messages, either 'asc' or 'desc'. Defaults to 'asc'.\n",
      " |          limit (int, optional): The number of messages to retrieve. Defaults to 20.\n",
      " |      \n",
      " |      Returns:\n",
      " |          list: A list of message objects.\n",
      " |  \n",
      " |  retrieve_messages(self, thread_id, order='desc', limit=20)\n",
      " |      Retrieves messages from a specified thread using the MessageManager.\n",
      " |      \n",
      " |      Args:\n",
      " |          thread_id (str): The ID of the thread.\n",
      " |          order (str, optional): The order in which to retrieve messages, either 'asc' or 'desc'. Defaults to 'desc'.\n",
      " |          limit (int, optional): The number of messages to retrieve. Defaults to 20.\n",
      " |      \n",
      " |      Returns:\n",
      " |          list: A list of dictionaries containing the message ID, role, and content of each message.\n",
      " |  \n",
      " |  retrieve_messages_dynamically(self, thread_id, order='asc', limit=20, retrieve_all=False, last_retrieved_id=None)\n",
      " |      Retrieves messages from a specified thread dynamically.\n",
      " |      \n",
      " |      Args:\n",
      " |          thread_id (str): The ID of the thread from which to retrieve messages.\n",
      " |          order (str, optional): The order in which to retrieve messages, either 'asc' or 'desc'. Defaults to 'asc'.\n",
      " |          limit (int, optional): The maximum number of messages to retrieve in a single request. Defaults to 20.\n",
      " |          retrieve_all (bool, optional): Whether to retrieve all messages in the thread. If False, only retrieves up to the limit. Defaults to False.\n",
      " |          last_retrieved_id (str, optional): The ID of the last retrieved message to fetch messages after it. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          list: A list of message objects retrieved from the thread.\n",
      " |      \n",
      " |      Raises:\n",
      " |          OpenAIError: If the API call to retrieve messages fails.\n",
      " |          Exception: If an unexpected error occurs.\n",
      " |  \n",
      " |  retrieve_thread(self, thread_id)\n",
      " |      Retrieves details of a specific thread by its ID using the ThreadManager.\n",
      " |      \n",
      " |      Args:\n",
      " |          thread_id (str): The ID of the thread to retrieve.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: The thread object.\n",
      " |  \n",
      " |  retrieve_vector_store_details(self, vector_store_id)\n",
      " |      Retrieves detailed information about a specific vector store using the VectorStoreManager.\n",
      " |      \n",
      " |      Args:\n",
      " |          vector_store_id (str): The ID of the vector store.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: The vector store object with detailed information.\n",
      " |  \n",
      " |  save_processed_content(self, from_assistant_id, to_assistant_id, processed_content)\n",
      " |      Saves the processed user content using the from_assistant_id and to_assistant_id.\n",
      " |      \n",
      " |      Args:\n",
      " |          from_assistant_id (str): The assistant identifier from which the content originates.\n",
      " |          to_assistant_id (str): The assistant identifier to which the content is directed.\n",
      " |          processed_content (str): The processed content to store.\n",
      " |      \n",
      " |      Returns:\n",
      " |          bool: True if content is saved successfully, False otherwise.\n",
      " |  \n",
      " |  search_files_in_vector_store(self, vector_store_id, query)\n",
      " |      Searches for files in a vector store based on a query using the VectorStoreManager.\n",
      " |      \n",
      " |      Args:\n",
      " |          vector_store_id (str): The ID of the vector store.\n",
      " |          query (str): The search query.\n",
      " |      \n",
      " |      Returns:\n",
      " |          list: A list of search results.\n",
      " |  \n",
      " |  thread_initialization(self, assistant_id)\n",
      " |      Initializes a new thread for the given assistant ID if it does not already exist,\n",
      " |      and sets its status to 'initialized'.\n",
      " |      \n",
      " |      Args:\n",
      " |          assistant_id (str): The unique identifier for the assistant.\n",
      " |      \n",
      " |      Returns:\n",
      " |          str: The thread ID of the newly created or existing thread.\n",
      " |  \n",
      " |  update_assistant_in_thread(self, assistant_id, thread_id)\n",
      " |      Updates the assistant settings in a thread by submitting an update message and creating a run.\n",
      " |      \n",
      " |      Args:\n",
      " |          assistant_id (str): The unique identifier for the assistant.\n",
      " |          thread_id (str): The thread identifier used for conversation.\n",
      " |      \n",
      " |      Returns:\n",
      " |          bool: True if the update is successful, False otherwise.\n",
      " |  \n",
      " |  update_assistant_with_vector_store(self, assistant_id, vector_store_id)\n",
      " |      Updates an assistant to use the new vector store using the VectorStoreManager.\n",
      " |      \n",
      " |      Args:\n",
      " |          assistant_id (str): The ID of the assistant.\n",
      " |          vector_store_id (str): The ID of the vector store.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: The updated assistant object.\n",
      " |  \n",
      " |  update_thread(self, thread_id, metadata=None, tool_resources=None)\n",
      " |      Updates a thread with the given details using the ThreadManager.\n",
      " |      \n",
      " |      Args:\n",
      " |          thread_id (str): The ID of the thread to update.\n",
      " |          metadata (dict, optional): Metadata to update for the thread.\n",
      " |          tool_resources (dict, optional): Tool resources to update for the thread.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: The updated thread object.\n",
      " |  \n",
      " |  upload_files_and_poll(self, vector_store_id, file_paths)\n",
      " |      Uploads files to a vector store and polls the status of the file batch for completion using the VectorStoreManager.\n",
      " |      \n",
      " |      Args:\n",
      " |          vector_store_id (str): The ID of the vector store.\n",
      " |          file_paths (list): A list of file paths to upload.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: The file batch object after upload and completion.\n",
      " |  \n",
      " |  wait_for_run_completion(self, thread_id)\n",
      " |      Waits for the completion of a run on a specified thread using the RunManager.\n",
      " |      \n",
      " |      Args:\n",
      " |          thread_id (str): The ID of the thread to wait for run completion.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from flexiai.core.flexiai_client import FlexiAI\n",
    "\n",
    "# Initialize FlexiAI\n",
    "flexiai = FlexiAI()\n",
    "\n",
    "# Access the client object\n",
    "client = flexiai.client\n",
    "\n",
    "# Print the type of client to verify\n",
    "print(type(client))\n",
    "\n",
    "# List all methods and attributes of flexiai\n",
    "print(dir(flexiai))\n",
    "\n",
    "# Detailed help on FlexiAI class\n",
    "help(flexiai)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_client', '_delete', '_get', '_get_api_list', '_patch', '_post', '_put', '_sleep', 'assistants', 'threads', 'vector_stores', 'with_raw_response', 'with_streaming_response']\n",
      "Help on Beta in module openai.resources.beta.beta object:\n",
      "\n",
      "class Beta(openai._resource.SyncAPIResource)\n",
      " |  Beta(client: 'OpenAI') -> 'None'\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Beta\n",
      " |      openai._resource.SyncAPIResource\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  assistants = <functools.cached_property object>\n",
      " |  threads = <functools.cached_property object>\n",
      " |  vector_stores = <functools.cached_property object>\n",
      " |  with_raw_response = <functools.cached_property object>\n",
      " |  with_streaming_response = <functools.cached_property object>\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from openai._resource.SyncAPIResource:\n",
      " |  \n",
      " |  __init__(self, client: 'OpenAI') -> 'None'\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from openai._resource.SyncAPIResource:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dir(client.beta))\n",
    "help(client.beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_client', '_delete', '_get', '_get_api_list', '_patch', '_post', '_put', '_sleep', 'create', 'delete', 'list', 'retrieve', 'update', 'with_raw_response', 'with_streaming_response']\n",
      "Help on Assistants in module openai.resources.beta.assistants object:\n",
      "\n",
      "class Assistants(openai._resource.SyncAPIResource)\n",
      " |  Assistants(client: 'OpenAI') -> 'None'\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Assistants\n",
      " |      openai._resource.SyncAPIResource\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  create(self, *, model: \"Union[str, Literal['gpt-4o', 'gpt-4o-2024-05-13', 'gpt-4-turbo', 'gpt-4-turbo-2024-04-09', 'gpt-4-0125-preview', 'gpt-4-turbo-preview', 'gpt-4-1106-preview', 'gpt-4-vision-preview', 'gpt-4', 'gpt-4-0314', 'gpt-4-0613', 'gpt-4-32k', 'gpt-4-32k-0314', 'gpt-4-32k-0613', 'gpt-3.5-turbo', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-1106', 'gpt-3.5-turbo-0125', 'gpt-3.5-turbo-16k-0613']]\", description: 'Optional[str] | NotGiven' = NOT_GIVEN, instructions: 'Optional[str] | NotGiven' = NOT_GIVEN, metadata: 'Optional[object] | NotGiven' = NOT_GIVEN, name: 'Optional[str] | NotGiven' = NOT_GIVEN, response_format: 'Optional[AssistantResponseFormatOptionParam] | NotGiven' = NOT_GIVEN, temperature: 'Optional[float] | NotGiven' = NOT_GIVEN, tool_resources: 'Optional[assistant_create_params.ToolResources] | NotGiven' = NOT_GIVEN, tools: 'Iterable[AssistantToolParam] | NotGiven' = NOT_GIVEN, top_p: 'Optional[float] | NotGiven' = NOT_GIVEN, extra_headers: 'Headers | None' = None, extra_query: 'Query | None' = None, extra_body: 'Body | None' = None, timeout: 'float | httpx.Timeout | None | NotGiven' = NOT_GIVEN) -> 'Assistant'\n",
      " |      Create an assistant with a model and instructions.\n",
      " |      \n",
      " |      Args:\n",
      " |        model: ID of the model to use. You can use the\n",
      " |            [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n",
      " |            see all of your available models, or see our\n",
      " |            [Model overview](https://platform.openai.com/docs/models/overview) for\n",
      " |            descriptions of them.\n",
      " |      \n",
      " |        description: The description of the assistant. The maximum length is 512 characters.\n",
      " |      \n",
      " |        instructions: The system instructions that the assistant uses. The maximum length is 256,000\n",
      " |            characters.\n",
      " |      \n",
      " |        metadata: Set of 16 key-value pairs that can be attached to an object. This can be useful\n",
      " |            for storing additional information about the object in a structured format. Keys\n",
      " |            can be a maximum of 64 characters long and values can be a maxium of 512\n",
      " |            characters long.\n",
      " |      \n",
      " |        name: The name of the assistant. The maximum length is 256 characters.\n",
      " |      \n",
      " |        response_format: Specifies the format that the model must output. Compatible with\n",
      " |            [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n",
      " |            [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n",
      " |            and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n",
      " |      \n",
      " |            Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n",
      " |            message the model generates is valid JSON.\n",
      " |      \n",
      " |            **Important:** when using JSON mode, you **must** also instruct the model to\n",
      " |            produce JSON yourself via a system or user message. Without this, the model may\n",
      " |            generate an unending stream of whitespace until the generation reaches the token\n",
      " |            limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n",
      " |            the message content may be partially cut off if `finish_reason=\"length\"`, which\n",
      " |            indicates the generation exceeded `max_tokens` or the conversation exceeded the\n",
      " |            max context length.\n",
      " |      \n",
      " |        temperature: What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n",
      " |            make the output more random, while lower values like 0.2 will make it more\n",
      " |            focused and deterministic.\n",
      " |      \n",
      " |        tool_resources: A set of resources that are used by the assistant's tools. The resources are\n",
      " |            specific to the type of tool. For example, the `code_interpreter` tool requires\n",
      " |            a list of file IDs, while the `file_search` tool requires a list of vector store\n",
      " |            IDs.\n",
      " |      \n",
      " |        tools: A list of tool enabled on the assistant. There can be a maximum of 128 tools per\n",
      " |            assistant. Tools can be of types `code_interpreter`, `file_search`, or\n",
      " |            `function`.\n",
      " |      \n",
      " |        top_p: An alternative to sampling with temperature, called nucleus sampling, where the\n",
      " |            model considers the results of the tokens with top_p probability mass. So 0.1\n",
      " |            means only the tokens comprising the top 10% probability mass are considered.\n",
      " |      \n",
      " |            We generally recommend altering this or temperature but not both.\n",
      " |      \n",
      " |        extra_headers: Send extra headers\n",
      " |      \n",
      " |        extra_query: Add additional query parameters to the request\n",
      " |      \n",
      " |        extra_body: Add additional JSON properties to the request\n",
      " |      \n",
      " |        timeout: Override the client-level default timeout for this request, in seconds\n",
      " |  \n",
      " |  delete(self, assistant_id: 'str', *, extra_headers: 'Headers | None' = None, extra_query: 'Query | None' = None, extra_body: 'Body | None' = None, timeout: 'float | httpx.Timeout | None | NotGiven' = NOT_GIVEN) -> 'AssistantDeleted'\n",
      " |      Delete an assistant.\n",
      " |      \n",
      " |      Args:\n",
      " |        extra_headers: Send extra headers\n",
      " |      \n",
      " |        extra_query: Add additional query parameters to the request\n",
      " |      \n",
      " |        extra_body: Add additional JSON properties to the request\n",
      " |      \n",
      " |        timeout: Override the client-level default timeout for this request, in seconds\n",
      " |  \n",
      " |  list(self, *, after: 'str | NotGiven' = NOT_GIVEN, before: 'str | NotGiven' = NOT_GIVEN, limit: 'int | NotGiven' = NOT_GIVEN, order: \"Literal['asc', 'desc'] | NotGiven\" = NOT_GIVEN, extra_headers: 'Headers | None' = None, extra_query: 'Query | None' = None, extra_body: 'Body | None' = None, timeout: 'float | httpx.Timeout | None | NotGiven' = NOT_GIVEN) -> 'SyncCursorPage[Assistant]'\n",
      " |      Returns a list of assistants.\n",
      " |      \n",
      " |      Args:\n",
      " |        after: A cursor for use in pagination.\n",
      " |      \n",
      " |      `after` is an object ID that defines your place\n",
      " |            in the list. For instance, if you make a list request and receive 100 objects,\n",
      " |            ending with obj_foo, your subsequent call can include after=obj_foo in order to\n",
      " |            fetch the next page of the list.\n",
      " |      \n",
      " |        before: A cursor for use in pagination. `before` is an object ID that defines your place\n",
      " |            in the list. For instance, if you make a list request and receive 100 objects,\n",
      " |            ending with obj_foo, your subsequent call can include before=obj_foo in order to\n",
      " |            fetch the previous page of the list.\n",
      " |      \n",
      " |        limit: A limit on the number of objects to be returned. Limit can range between 1 and\n",
      " |            100, and the default is 20.\n",
      " |      \n",
      " |        order: Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n",
      " |            order and `desc` for descending order.\n",
      " |      \n",
      " |        extra_headers: Send extra headers\n",
      " |      \n",
      " |        extra_query: Add additional query parameters to the request\n",
      " |      \n",
      " |        extra_body: Add additional JSON properties to the request\n",
      " |      \n",
      " |        timeout: Override the client-level default timeout for this request, in seconds\n",
      " |  \n",
      " |  retrieve(self, assistant_id: 'str', *, extra_headers: 'Headers | None' = None, extra_query: 'Query | None' = None, extra_body: 'Body | None' = None, timeout: 'float | httpx.Timeout | None | NotGiven' = NOT_GIVEN) -> 'Assistant'\n",
      " |      Retrieves an assistant.\n",
      " |      \n",
      " |      Args:\n",
      " |        extra_headers: Send extra headers\n",
      " |      \n",
      " |        extra_query: Add additional query parameters to the request\n",
      " |      \n",
      " |        extra_body: Add additional JSON properties to the request\n",
      " |      \n",
      " |        timeout: Override the client-level default timeout for this request, in seconds\n",
      " |  \n",
      " |  update(self, assistant_id: 'str', *, description: 'Optional[str] | NotGiven' = NOT_GIVEN, instructions: 'Optional[str] | NotGiven' = NOT_GIVEN, metadata: 'Optional[object] | NotGiven' = NOT_GIVEN, model: 'str | NotGiven' = NOT_GIVEN, name: 'Optional[str] | NotGiven' = NOT_GIVEN, response_format: 'Optional[AssistantResponseFormatOptionParam] | NotGiven' = NOT_GIVEN, temperature: 'Optional[float] | NotGiven' = NOT_GIVEN, tool_resources: 'Optional[assistant_update_params.ToolResources] | NotGiven' = NOT_GIVEN, tools: 'Iterable[AssistantToolParam] | NotGiven' = NOT_GIVEN, top_p: 'Optional[float] | NotGiven' = NOT_GIVEN, extra_headers: 'Headers | None' = None, extra_query: 'Query | None' = None, extra_body: 'Body | None' = None, timeout: 'float | httpx.Timeout | None | NotGiven' = NOT_GIVEN) -> 'Assistant'\n",
      " |      Modifies an assistant.\n",
      " |      \n",
      " |      Args:\n",
      " |        description: The description of the assistant.\n",
      " |      \n",
      " |      The maximum length is 512 characters.\n",
      " |      \n",
      " |        instructions: The system instructions that the assistant uses. The maximum length is 256,000\n",
      " |            characters.\n",
      " |      \n",
      " |        metadata: Set of 16 key-value pairs that can be attached to an object. This can be useful\n",
      " |            for storing additional information about the object in a structured format. Keys\n",
      " |            can be a maximum of 64 characters long and values can be a maxium of 512\n",
      " |            characters long.\n",
      " |      \n",
      " |        model: ID of the model to use. You can use the\n",
      " |            [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n",
      " |            see all of your available models, or see our\n",
      " |            [Model overview](https://platform.openai.com/docs/models/overview) for\n",
      " |            descriptions of them.\n",
      " |      \n",
      " |        name: The name of the assistant. The maximum length is 256 characters.\n",
      " |      \n",
      " |        response_format: Specifies the format that the model must output. Compatible with\n",
      " |            [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n",
      " |            [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n",
      " |            and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n",
      " |      \n",
      " |            Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n",
      " |            message the model generates is valid JSON.\n",
      " |      \n",
      " |            **Important:** when using JSON mode, you **must** also instruct the model to\n",
      " |            produce JSON yourself via a system or user message. Without this, the model may\n",
      " |            generate an unending stream of whitespace until the generation reaches the token\n",
      " |            limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n",
      " |            the message content may be partially cut off if `finish_reason=\"length\"`, which\n",
      " |            indicates the generation exceeded `max_tokens` or the conversation exceeded the\n",
      " |            max context length.\n",
      " |      \n",
      " |        temperature: What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n",
      " |            make the output more random, while lower values like 0.2 will make it more\n",
      " |            focused and deterministic.\n",
      " |      \n",
      " |        tool_resources: A set of resources that are used by the assistant's tools. The resources are\n",
      " |            specific to the type of tool. For example, the `code_interpreter` tool requires\n",
      " |            a list of file IDs, while the `file_search` tool requires a list of vector store\n",
      " |            IDs.\n",
      " |      \n",
      " |        tools: A list of tool enabled on the assistant. There can be a maximum of 128 tools per\n",
      " |            assistant. Tools can be of types `code_interpreter`, `file_search`, or\n",
      " |            `function`.\n",
      " |      \n",
      " |        top_p: An alternative to sampling with temperature, called nucleus sampling, where the\n",
      " |            model considers the results of the tokens with top_p probability mass. So 0.1\n",
      " |            means only the tokens comprising the top 10% probability mass are considered.\n",
      " |      \n",
      " |            We generally recommend altering this or temperature but not both.\n",
      " |      \n",
      " |        extra_headers: Send extra headers\n",
      " |      \n",
      " |        extra_query: Add additional query parameters to the request\n",
      " |      \n",
      " |        extra_body: Add additional JSON properties to the request\n",
      " |      \n",
      " |        timeout: Override the client-level default timeout for this request, in seconds\n",
      " |  \n",
      " |  with_raw_response = <functools.cached_property object>\n",
      " |  with_streaming_response = <functools.cached_property object>\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from openai._resource.SyncAPIResource:\n",
      " |  \n",
      " |  __init__(self, client: 'OpenAI') -> 'None'\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from openai._resource.SyncAPIResource:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dir(client.beta.assistants))\n",
    "help(client.beta.assistants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_client', '_delete', '_get', '_get_api_list', '_patch', '_post', '_put', '_sleep', 'create', 'create_and_run', 'create_and_run_poll', 'create_and_run_stream', 'delete', 'messages', 'retrieve', 'runs', 'update', 'with_raw_response', 'with_streaming_response']\n",
      "Help on Threads in module openai.resources.beta.threads.threads object:\n",
      "\n",
      "class Threads(openai._resource.SyncAPIResource)\n",
      " |  Threads(client: 'OpenAI') -> 'None'\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Threads\n",
      " |      openai._resource.SyncAPIResource\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  create(self, *, messages: 'Iterable[thread_create_params.Message] | NotGiven' = NOT_GIVEN, metadata: 'Optional[object] | NotGiven' = NOT_GIVEN, tool_resources: 'Optional[thread_create_params.ToolResources] | NotGiven' = NOT_GIVEN, extra_headers: 'Headers | None' = None, extra_query: 'Query | None' = None, extra_body: 'Body | None' = None, timeout: 'float | httpx.Timeout | None | NotGiven' = NOT_GIVEN) -> 'Thread'\n",
      " |      Create a thread.\n",
      " |      \n",
      " |      Args:\n",
      " |        messages: A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n",
      " |            start the thread with.\n",
      " |      \n",
      " |        metadata: Set of 16 key-value pairs that can be attached to an object. This can be useful\n",
      " |            for storing additional information about the object in a structured format. Keys\n",
      " |            can be a maximum of 64 characters long and values can be a maxium of 512\n",
      " |            characters long.\n",
      " |      \n",
      " |        tool_resources: A set of resources that are made available to the assistant's tools in this\n",
      " |            thread. The resources are specific to the type of tool. For example, the\n",
      " |            `code_interpreter` tool requires a list of file IDs, while the `file_search`\n",
      " |            tool requires a list of vector store IDs.\n",
      " |      \n",
      " |        extra_headers: Send extra headers\n",
      " |      \n",
      " |        extra_query: Add additional query parameters to the request\n",
      " |      \n",
      " |        extra_body: Add additional JSON properties to the request\n",
      " |      \n",
      " |        timeout: Override the client-level default timeout for this request, in seconds\n",
      " |  \n",
      " |  create_and_run(self, *, assistant_id: 'str', instructions: 'Optional[str] | NotGiven' = NOT_GIVEN, max_completion_tokens: 'Optional[int] | NotGiven' = NOT_GIVEN, max_prompt_tokens: 'Optional[int] | NotGiven' = NOT_GIVEN, metadata: 'Optional[object] | NotGiven' = NOT_GIVEN, model: \"Union[str, Literal['gpt-4o', 'gpt-4o-2024-05-13', 'gpt-4-turbo', 'gpt-4-turbo-2024-04-09', 'gpt-4-0125-preview', 'gpt-4-turbo-preview', 'gpt-4-1106-preview', 'gpt-4-vision-preview', 'gpt-4', 'gpt-4-0314', 'gpt-4-0613', 'gpt-4-32k', 'gpt-4-32k-0314', 'gpt-4-32k-0613', 'gpt-3.5-turbo', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-1106', 'gpt-3.5-turbo-0125', 'gpt-3.5-turbo-16k-0613'], None] | NotGiven\" = NOT_GIVEN, parallel_tool_calls: 'bool | NotGiven' = NOT_GIVEN, response_format: 'Optional[AssistantResponseFormatOptionParam] | NotGiven' = NOT_GIVEN, stream: 'Optional[Literal[False]] | Literal[True] | NotGiven' = NOT_GIVEN, temperature: 'Optional[float] | NotGiven' = NOT_GIVEN, thread: 'thread_create_and_run_params.Thread | NotGiven' = NOT_GIVEN, tool_choice: 'Optional[AssistantToolChoiceOptionParam] | NotGiven' = NOT_GIVEN, tool_resources: 'Optional[thread_create_and_run_params.ToolResources] | NotGiven' = NOT_GIVEN, tools: 'Optional[Iterable[thread_create_and_run_params.Tool]] | NotGiven' = NOT_GIVEN, top_p: 'Optional[float] | NotGiven' = NOT_GIVEN, truncation_strategy: 'Optional[thread_create_and_run_params.TruncationStrategy] | NotGiven' = NOT_GIVEN, extra_headers: 'Headers | None' = None, extra_query: 'Query | None' = None, extra_body: 'Body | None' = None, timeout: 'float | httpx.Timeout | None | NotGiven' = NOT_GIVEN) -> 'Run | Stream[AssistantStreamEvent]'\n",
      " |  \n",
      " |  create_and_run_poll(self, *, assistant_id: 'str', instructions: 'Optional[str] | NotGiven' = NOT_GIVEN, max_completion_tokens: 'Optional[int] | NotGiven' = NOT_GIVEN, max_prompt_tokens: 'Optional[int] | NotGiven' = NOT_GIVEN, metadata: 'Optional[object] | NotGiven' = NOT_GIVEN, model: \"Union[str, Literal['gpt-4o', 'gpt-4o-2024-05-13', 'gpt-4-turbo', 'gpt-4-turbo-2024-04-09', 'gpt-4-0125-preview', 'gpt-4-turbo-preview', 'gpt-4-1106-preview', 'gpt-4-vision-preview', 'gpt-4', 'gpt-4-0314', 'gpt-4-0613', 'gpt-4-32k', 'gpt-4-32k-0314', 'gpt-4-32k-0613', 'gpt-3.5-turbo', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-1106', 'gpt-3.5-turbo-0125', 'gpt-3.5-turbo-16k-0613'], None] | NotGiven\" = NOT_GIVEN, response_format: 'Optional[AssistantResponseFormatOptionParam] | NotGiven' = NOT_GIVEN, temperature: 'Optional[float] | NotGiven' = NOT_GIVEN, thread: 'thread_create_and_run_params.Thread | NotGiven' = NOT_GIVEN, tool_choice: 'Optional[AssistantToolChoiceOptionParam] | NotGiven' = NOT_GIVEN, tool_resources: 'Optional[thread_create_and_run_params.ToolResources] | NotGiven' = NOT_GIVEN, tools: 'Optional[Iterable[thread_create_and_run_params.Tool]] | NotGiven' = NOT_GIVEN, top_p: 'Optional[float] | NotGiven' = NOT_GIVEN, truncation_strategy: 'Optional[thread_create_and_run_params.TruncationStrategy] | NotGiven' = NOT_GIVEN, poll_interval_ms: 'int | NotGiven' = NOT_GIVEN, extra_headers: 'Headers | None' = None, extra_query: 'Query | None' = None, extra_body: 'Body | None' = None, timeout: 'float | httpx.Timeout | None | NotGiven' = NOT_GIVEN) -> 'Run'\n",
      " |      A helper to create a thread, start a run and then poll for a terminal state.\n",
      " |      More information on Run lifecycles can be found here:\n",
      " |      https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n",
      " |  \n",
      " |  create_and_run_stream(self, *, assistant_id: 'str', instructions: 'Optional[str] | NotGiven' = NOT_GIVEN, max_completion_tokens: 'Optional[int] | NotGiven' = NOT_GIVEN, max_prompt_tokens: 'Optional[int] | NotGiven' = NOT_GIVEN, metadata: 'Optional[object] | NotGiven' = NOT_GIVEN, model: \"Union[str, Literal['gpt-4o', 'gpt-4o-2024-05-13', 'gpt-4-turbo', 'gpt-4-turbo-2024-04-09', 'gpt-4-0125-preview', 'gpt-4-turbo-preview', 'gpt-4-1106-preview', 'gpt-4-vision-preview', 'gpt-4', 'gpt-4-0314', 'gpt-4-0613', 'gpt-4-32k', 'gpt-4-32k-0314', 'gpt-4-32k-0613', 'gpt-3.5-turbo', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-1106', 'gpt-3.5-turbo-0125', 'gpt-3.5-turbo-16k-0613'], None] | NotGiven\" = NOT_GIVEN, response_format: 'Optional[AssistantResponseFormatOptionParam] | NotGiven' = NOT_GIVEN, temperature: 'Optional[float] | NotGiven' = NOT_GIVEN, thread: 'thread_create_and_run_params.Thread | NotGiven' = NOT_GIVEN, tool_choice: 'Optional[AssistantToolChoiceOptionParam] | NotGiven' = NOT_GIVEN, tool_resources: 'Optional[thread_create_and_run_params.ToolResources] | NotGiven' = NOT_GIVEN, tools: 'Optional[Iterable[thread_create_and_run_params.Tool]] | NotGiven' = NOT_GIVEN, top_p: 'Optional[float] | NotGiven' = NOT_GIVEN, truncation_strategy: 'Optional[thread_create_and_run_params.TruncationStrategy] | NotGiven' = NOT_GIVEN, event_handler: 'AssistantEventHandlerT | None' = None, extra_headers: 'Headers | None' = None, extra_query: 'Query | None' = None, extra_body: 'Body | None' = None, timeout: 'float | httpx.Timeout | None | NotGiven' = NOT_GIVEN) -> 'AssistantStreamManager[AssistantEventHandler] | AssistantStreamManager[AssistantEventHandlerT]'\n",
      " |      Create a thread and stream the run back\n",
      " |  \n",
      " |  delete(self, thread_id: 'str', *, extra_headers: 'Headers | None' = None, extra_query: 'Query | None' = None, extra_body: 'Body | None' = None, timeout: 'float | httpx.Timeout | None | NotGiven' = NOT_GIVEN) -> 'ThreadDeleted'\n",
      " |      Delete a thread.\n",
      " |      \n",
      " |      Args:\n",
      " |        extra_headers: Send extra headers\n",
      " |      \n",
      " |        extra_query: Add additional query parameters to the request\n",
      " |      \n",
      " |        extra_body: Add additional JSON properties to the request\n",
      " |      \n",
      " |        timeout: Override the client-level default timeout for this request, in seconds\n",
      " |  \n",
      " |  messages = <functools.cached_property object>\n",
      " |  retrieve(self, thread_id: 'str', *, extra_headers: 'Headers | None' = None, extra_query: 'Query | None' = None, extra_body: 'Body | None' = None, timeout: 'float | httpx.Timeout | None | NotGiven' = NOT_GIVEN) -> 'Thread'\n",
      " |      Retrieves a thread.\n",
      " |      \n",
      " |      Args:\n",
      " |        extra_headers: Send extra headers\n",
      " |      \n",
      " |        extra_query: Add additional query parameters to the request\n",
      " |      \n",
      " |        extra_body: Add additional JSON properties to the request\n",
      " |      \n",
      " |        timeout: Override the client-level default timeout for this request, in seconds\n",
      " |  \n",
      " |  runs = <functools.cached_property object>\n",
      " |  update(self, thread_id: 'str', *, metadata: 'Optional[object] | NotGiven' = NOT_GIVEN, tool_resources: 'Optional[thread_update_params.ToolResources] | NotGiven' = NOT_GIVEN, extra_headers: 'Headers | None' = None, extra_query: 'Query | None' = None, extra_body: 'Body | None' = None, timeout: 'float | httpx.Timeout | None | NotGiven' = NOT_GIVEN) -> 'Thread'\n",
      " |      Modifies a thread.\n",
      " |      \n",
      " |      Args:\n",
      " |        metadata: Set of 16 key-value pairs that can be attached to an object. This can be useful\n",
      " |            for storing additional information about the object in a structured format. Keys\n",
      " |            can be a maximum of 64 characters long and values can be a maxium of 512\n",
      " |            characters long.\n",
      " |      \n",
      " |        tool_resources: A set of resources that are made available to the assistant's tools in this\n",
      " |            thread. The resources are specific to the type of tool. For example, the\n",
      " |            `code_interpreter` tool requires a list of file IDs, while the `file_search`\n",
      " |            tool requires a list of vector store IDs.\n",
      " |      \n",
      " |        extra_headers: Send extra headers\n",
      " |      \n",
      " |        extra_query: Add additional query parameters to the request\n",
      " |      \n",
      " |        extra_body: Add additional JSON properties to the request\n",
      " |      \n",
      " |        timeout: Override the client-level default timeout for this request, in seconds\n",
      " |  \n",
      " |  with_raw_response = <functools.cached_property object>\n",
      " |  with_streaming_response = <functools.cached_property object>\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from openai._resource.SyncAPIResource:\n",
      " |  \n",
      " |  __init__(self, client: 'OpenAI') -> 'None'\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from openai._resource.SyncAPIResource:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dir(client.beta.threads))\n",
    "help(client.beta.threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_beta', 'assistants', 'threads', 'vector_stores']\n"
     ]
    }
   ],
   "source": [
    "print(dir(client.beta.with_raw_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_beta', 'assistants', 'threads', 'vector_stores']\n",
      "Help on BetaWithStreamingResponse in module openai.resources.beta.beta object:\n",
      "\n",
      "class BetaWithStreamingResponse(builtins.object)\n",
      " |  BetaWithStreamingResponse(beta: 'Beta') -> 'None'\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, beta: 'Beta') -> 'None'\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  assistants = <functools.cached_property object>\n",
      " |  threads = <functools.cached_property object>\n",
      " |  vector_stores = <functools.cached_property object>\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dir(client.beta.with_streaming_response))\n",
    "help(client.beta.with_streaming_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
