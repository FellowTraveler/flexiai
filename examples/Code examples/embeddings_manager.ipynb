{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /home/razvansavin/Proiecte/flexiai/examples/Code examples\n",
      "Changed Directory to: /home/razvansavin/Proiecte/flexiai\n",
      "Project root added to sys.path\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Check current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Current Directory: {current_dir}\")\n",
    "\n",
    "# Change to your project root directory\n",
    "project_root = '/home/razvansavin/Proiecte/flexiai'\n",
    "os.chdir(project_root)\n",
    "print(f\"Changed Directory to: {os.getcwd()}\")\n",
    "\n",
    "# Add project root directory to sys.path\n",
    "sys.path.append(project_root)\n",
    "print(f\"Project root added to sys.path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/razvansavin/Proiecte/flexiai\n",
      "Log directory '/home/razvansavin/Proiecte/flexiai/logs' created/exists.\n",
      "Embedding created successfully\n",
      "[ 0.00171095 -0.00803227 -0.01134489 -0.01328466  0.00326994  0.00642376\n",
      " -0.00899532 -0.00340483  0.00771808 -0.04169128  0.02406948  0.02852274\n",
      "  0.0284681  -0.02176088 -0.00404687  0.01622846  0.02009432 -0.0105321\n",
      "  0.01150199  0.00212759]...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from flexiai.core.flexiai_client import FlexiAI\n",
    "from flexiai.config.logging_config import setup_logging\n",
    "\n",
    "\n",
    "# Set up logging\n",
    "setup_logging()\n",
    "\n",
    "# Initialize FlexiAI\n",
    "flexiai = FlexiAI()\n",
    "\n",
    "# Create an embedding\n",
    "text = \"OpenAI provides powerful tools for developers.\"\n",
    "try:\n",
    "    embedding = flexiai.embedding_manager.create_embeddings(text)\n",
    "    print(\"Embedding created successfully\")\n",
    "    print(f\"{embedding[:20]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating embedding: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/razvansavin/.conda_flexi/lib/python3.11/site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /home/razvansavin/.conda_flexi/lib/python3.11/site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/razvansavin/.conda_flexi/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/razvansavin/.conda_flexi/lib/python3.11/site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/razvansavin/.conda_flexi/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/razvansavin/.conda_flexi/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Text Similarity and Search**\n",
    "\n",
    "#### Example: Finding Similar Texts\n",
    "You can use embeddings to find texts that are similar to a given input text. This is useful for search engines, recommendation systems, and clustering similar documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar text: Developers use OpenAI tools for creating applications.\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Calculate the cosine similarity between two vectors.\"\"\"\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Embedding for the input text\n",
    "input_text = \"OpenAI provides powerful tools for developers.\"\n",
    "input_embedding = flexiai.embedding_manager.create_embeddings(input_text)\n",
    "\n",
    "# Embeddings for a list of texts\n",
    "texts = [\n",
    "    \"Developers use OpenAI tools for creating applications.\",\n",
    "    \"AI is revolutionizing technology.\",\n",
    "    \"Cooking recipes are easy to find online.\",\n",
    "]\n",
    "embeddings = [flexiai.embedding_manager.create_embeddings(text) for text in texts]\n",
    "\n",
    "# Find the most similar text\n",
    "similarities = [cosine_similarity(input_embedding, emb) for emb in embeddings]\n",
    "most_similar_index = np.argmax(similarities)\n",
    "print(f\"Most similar text: {texts[most_similar_index]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. **Clustering**\n",
    "\n",
    "#### Example: Clustering Texts\n",
    "Clustering texts based on their embeddings can help in organizing and categorizing large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      " - AI is revolutionizing technology.\n",
      " - Artificial intelligence is a growing field.\n",
      " - Machine learning is a subset of AI.\n",
      " - Technology is advancing rapidly.\n",
      " - AI is used in various industries.\n",
      "Cluster 1:\n",
      " - Cooking recipes are easy to find online.\n",
      " - Food blogs are popular.\n",
      " - I love baking new recipes.\n",
      " - Recipes for healthy eating are trending.\n",
      "Cluster 2:\n",
      " - OpenAI provides powerful tools for developers.\n",
      " - Developers use OpenAI tools for creating applications.\n",
      " - AI tools help developers build software.\n"
     ]
    }
   ],
   "source": [
    "# Example: Clustering Texts\n",
    "texts = [\n",
    "    \"OpenAI provides powerful tools for developers.\",\n",
    "    \"Developers use OpenAI tools for creating applications.\",\n",
    "    \"AI is revolutionizing technology.\",\n",
    "    \"Cooking recipes are easy to find online.\",\n",
    "    \"Artificial intelligence is a growing field.\",\n",
    "    \"Food blogs are popular.\",\n",
    "    \"Machine learning is a subset of AI.\",\n",
    "    \"I love baking new recipes.\",\n",
    "    \"AI tools help developers build software.\",\n",
    "    \"Technology is advancing rapidly.\",\n",
    "    \"Recipes for healthy eating are trending.\",\n",
    "    \"AI is used in various industries.\",\n",
    "]\n",
    "\n",
    "# Generate embeddings for texts\n",
    "embeddings = [flexiai.embedding_manager.create_embeddings(text) for text in texts]\n",
    "\n",
    "# Scale embeddings\n",
    "scaler = StandardScaler()\n",
    "scaled_embeddings = scaler.fit_transform(embeddings)\n",
    "\n",
    "# Clustering with KMeans\n",
    "num_clusters = 3\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(scaled_embeddings)\n",
    "\n",
    "# Print clustered texts\n",
    "for i in range(num_clusters):\n",
    "    cluster_texts = [texts[j] for j in range(len(texts)) if clusters[j] == i]\n",
    "    print(f\"Cluster {i}:\")\n",
    "    for text in cluster_texts:\n",
    "        print(f\" - {text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. **Semantic Search**\n",
    "\n",
    "#### Example: Implementing Semantic Search\n",
    "Semantic search uses embeddings to find relevant documents based on the meaning of the query rather than keyword matching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most relevant document: AI is revolutionizing technology.\n"
     ]
    }
   ],
   "source": [
    "# Example: Semantic Search\n",
    "query = \"How does AI impact technology?\"\n",
    "query_embedding = flexiai.embedding_manager.create_embeddings(query)\n",
    "\n",
    "# Assuming `documents` is a list of document texts and `doc_embeddings` is a list of their embeddings\n",
    "documents = [\n",
    "    \"AI is revolutionizing technology.\",\n",
    "    \"Cooking recipes are easy to find online.\",\n",
    "    \"Developers use OpenAI tools for creating applications.\",\n",
    "]\n",
    "doc_embeddings = [flexiai.embedding_manager.create_embeddings(doc) for doc in documents]\n",
    "\n",
    "# Find the most relevant document\n",
    "similarities = [cosine_similarity(query_embedding, emb) for emb in doc_embeddings]\n",
    "most_relevant_index = np.argmax(similarities)\n",
    "print(f\"Most relevant document: {documents[most_relevant_index]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. **Text Classification**\n",
    "\n",
    "#### Example: Classifying Texts\n",
    "Embeddings can be used as features for text classification tasks such as sentiment analysis, topic categorization, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: tech-related\n"
     ]
    }
   ],
   "source": [
    "# Example: Text Classification\n",
    "texts = [\n",
    "    \"I love using OpenAI tools.\",\n",
    "    \"AI is transforming the industry.\",\n",
    "    \"I found a great recipe for pasta.\",\n",
    "    \"Artificial intelligence is fascinating.\",\n",
    "]\n",
    "labels = [1, 1, 0, 1]  # 1 for tech-related, 0 for non-tech-related\n",
    "\n",
    "embeddings = [flexiai.embedding_manager.create_embeddings(text) for text in texts]\n",
    "\n",
    "# Train a simple classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(embeddings, labels)\n",
    "\n",
    "# Classify a new text\n",
    "new_text = \"Developers are creating amazing applications with AI.\"\n",
    "new_embedding = flexiai.embedding_manager.create_embeddings(new_text)\n",
    "predicted_label = classifier.predict([new_embedding])\n",
    "print(f\"Predicted label: {'tech-related' if predicted_label[0] == 1 else 'non-tech-related'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. **Question Answering**\n",
    "\n",
    "#### Example: Answering Questions with Context\n",
    "Using embeddings, you can implement a basic question-answering system that retrieves the most relevant answer from a given context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: OpenAI provides powerful tools for developers.\n"
     ]
    }
   ],
   "source": [
    "# Example: Question Answering\n",
    "context = [\n",
    "    \"OpenAI provides powerful tools for developers.\",\n",
    "    \"AI is revolutionizing technology.\",\n",
    "    \"Developers use OpenAI tools for creating applications.\",\n",
    "]\n",
    "question = \"What does OpenAI provide?\"\n",
    "\n",
    "# Embeddings for context sentences and question\n",
    "context_embeddings = [flexiai.embedding_manager.create_embeddings(sentence) for sentence in context]\n",
    "question_embedding = flexiai.embedding_manager.create_embeddings(question)\n",
    "\n",
    "# Find the most relevant context sentence\n",
    "similarities = [cosine_similarity(question_embedding, emb) for emb in context_embeddings]\n",
    "most_relevant_index = np.argmax(similarities)\n",
    "print(f\"Answer: {context[most_relevant_index]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. **Sentiment Analysis**\n",
    "\n",
    "#### Example: Sentiment Classification with Logistic Regression\n",
    "Using embeddings as features for training a sentiment classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 100.00%\n",
      "Text: 'OpenAI's tools are amazing!' - Sentiment: positive\n",
      "Text: 'I am very disappointed with the service.' - Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "texts = [\n",
    "    \"I love using OpenAI tools.\",\n",
    "    \"AI is revolutionizing the industry.\",\n",
    "    \"I found a great recipe for pasta.\",\n",
    "    \"Artificial intelligence is fascinating.\",\n",
    "    \"I am so frustrated with this service.\",\n",
    "    \"This is the worst experience I've ever had.\",\n",
    "]\n",
    "labels = [1, 1, 1, 1, 0, 0]  # 1 for positive, 0 for negative\n",
    "\n",
    "# Generate embeddings for texts using FlexiAI `create_embeddingss` function\n",
    "embeddings = [flexiai.embedding_manager.create_embeddings(text) for text in texts]\n",
    "\n",
    "# Filter out any None values if embedding generation failed for any text\n",
    "embeddings = [emb for emb in embeddings if emb is not None]\n",
    "labels = [label for emb, label in zip(embeddings, labels) if emb is not None]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_embeddings, test_embeddings, train_labels, test_labels = train_test_split(embeddings, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the logistic regression classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_embeddings, train_labels)\n",
    "\n",
    "# Evaluate the classifier\n",
    "predicted_test_labels = classifier.predict(test_embeddings)\n",
    "accuracy = accuracy_score(test_labels, predicted_test_labels)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Classify new texts\n",
    "new_texts = [\n",
    "    \"OpenAI's tools are amazing!\",\n",
    "    \"I am very disappointed with the service.\",\n",
    "]\n",
    "# Generate NEW embeddings for texts using FlexiAI `create_embeddingss` function\n",
    "new_embeddings = [flexiai.embedding_manager.create_embeddings(text) for text in new_texts]\n",
    "predicted_labels = classifier.predict(new_embeddings)\n",
    "\n",
    "for text, label in zip(new_texts, predicted_labels):\n",
    "    sentiment = 'positive' if label == 1 else 'negative'\n",
    "    print(f\"Text: '{text}' - Sentiment: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. **Enhanced Sentiment Analysis with Data Augmentation**\n",
    "\n",
    "#### Example: Sentiment Classification with Logistic Regression and Data Augmentation\n",
    "In this example, we improve sentiment classification by augmenting the data to create more variations of the texts. This helps in better generalization of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy: 96.00%\n",
      "Test Accuracy: 100.00%\n",
      "Precision: 100.00%\n",
      "Recall: 100.00%\n",
      "F1 Score: 100.00%\n",
      "Text: 'OpenAI's tools are amazing!' - Sentiment: positive\n",
      "Text: 'I am very disappointed with the service.' - Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "texts = [\n",
    "    \"I love using OpenAI tools.\",\n",
    "    \"AI is revolutionizing the industry.\",\n",
    "    \"I found a great recipe for pasta.\",\n",
    "    \"Artificial intelligence is fascinating.\",\n",
    "    \"I am so frustrated with this service.\",\n",
    "    \"This is the worst experience I've ever had.\",\n",
    "    \"I hate waiting in long lines.\",\n",
    "    \"The product quality is terrible.\",\n",
    "    \"The new feature is awesome!\",\n",
    "    \"I am very pleased with the customer support.\",\n",
    "]\n",
    "labels = [1, 1, 1, 1, 0, 0, 0, 0, 1, 1]  # 1 for positive, 0 for negative\n",
    "\n",
    "# Data augmentation: create slight variations of the texts\n",
    "augmented_texts = texts + [\n",
    "    \"I absolutely love using OpenAI tools.\",\n",
    "    \"The industry is being revolutionized by AI.\",\n",
    "    \"I discovered a fantastic recipe for pasta.\",\n",
    "    \"AI is incredibly fascinating.\",\n",
    "    \"This service is extremely frustrating.\",\n",
    "    \"I've never had a worse experience.\",\n",
    "    \"Waiting in long lines is so annoying.\",\n",
    "    \"The quality of the product is horrible.\",\n",
    "    \"The new feature is really awesome!\",\n",
    "    \"Customer support has been very pleasing.\",\n",
    "    \"Using OpenAI tools is such a pleasure.\",\n",
    "    \"AI is changing the world.\",\n",
    "    \"Found an amazing pasta recipe!\",\n",
    "    \"I find artificial intelligence really interesting.\",\n",
    "    \"This service makes me so angry.\",\n",
    "    \"Worst service experience ever.\",\n",
    "    \"I despise long wait times.\",\n",
    "    \"Product quality is very poor.\",\n",
    "    \"Loving the new feature!\",\n",
    "    \"Very satisfied with customer support.\",\n",
    "]\n",
    "augmented_labels = labels + labels + labels\n",
    "\n",
    "# Generate embeddings for texts\n",
    "embeddings = [flexiai.embedding_manager.create_embeddings(text) for text in augmented_texts]\n",
    "\n",
    "# Filter out any None values if embedding generation failed for any text\n",
    "embeddings = [emb for emb in embeddings if emb is not None]\n",
    "augmented_labels = [label for emb, label in zip(embeddings, augmented_labels) if emb is not None]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_embeddings, test_embeddings, train_labels, test_labels = train_test_split(embeddings, augmented_labels, test_size=0.2, random_state=42, stratify=augmented_labels)\n",
    "\n",
    "# Train the logistic regression classifier with regularization\n",
    "classifier = LogisticRegression(C=1.0, solver='liblinear')\n",
    "classifier.fit(train_embeddings, train_labels)\n",
    "\n",
    "# Cross-validation using StratifiedKFold to ensure balanced splits\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(classifier, train_embeddings, train_labels, cv=cv)\n",
    "\n",
    "print(f\"Cross-Validation Accuracy: {cv_scores.mean() * 100:.2f}%\")\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "predicted_test_labels = classifier.predict(test_embeddings)\n",
    "accuracy = accuracy_score(test_labels, predicted_test_labels)\n",
    "precision = precision_score(test_labels, predicted_test_labels)\n",
    "recall = recall_score(test_labels, predicted_test_labels)\n",
    "f1 = f1_score(test_labels, predicted_test_labels)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "# Classify new texts\n",
    "new_texts = [\n",
    "    \"OpenAI's tools are amazing!\",\n",
    "    \"I am very disappointed with the service.\",\n",
    "]\n",
    "new_embeddings = [flexiai.embedding_manager.create_embeddings(text) for text in new_texts]\n",
    "predicted_labels = classifier.predict(new_embeddings)\n",
    "\n",
    "for text, label in zip(new_texts, predicted_labels):\n",
    "    sentiment = 'positive' if label == 1 else 'negative'\n",
    "    print(f\"Text: '{text}' - Sentiment: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings and Labels:\n",
      "Label: 1, Embedding: [-0.02184969 -0.02521532 -0.00558695 -0.03346786  0.00782846]...\n",
      "Label: 1, Embedding: [-0.01700989 -0.02424673 -0.00913568 -0.00095357 -0.00373129]...\n",
      "Label: 1, Embedding: [ 0.01686893  0.00550202  0.00944137 -0.00730333  0.01237709]...\n",
      "Label: 1, Embedding: [-0.0104941  -0.00198581  0.01232169 -0.01587353  0.01007433]...\n",
      "Label: 0, Embedding: [-0.02796874 -0.00581143 -0.02613494 -0.00895791 -0.00475601]...\n",
      "Label: 0, Embedding: [-0.02066449 -0.01416779  0.01079451 -0.02041462 -0.03453244]...\n",
      "Label: 0, Embedding: [-2.92321499e-02  2.11152546e-05  1.04639269e-02 -1.25785656e-02\n",
      " -3.16231698e-02]...\n",
      "Label: 0, Embedding: [-0.00999594  0.00082101 -0.01090165 -0.00213042 -0.01635578]...\n",
      "Label: 1, Embedding: [-0.01405413  0.01471457  0.00048418 -0.03320684 -0.01682797]...\n",
      "Label: 1, Embedding: [-0.0072394  -0.00262535 -0.00274349 -0.03956399 -0.0264635 ]...\n",
      "Label: 1, Embedding: [-0.02164579 -0.02529381 -0.00410234 -0.03882243  0.00586577]...\n",
      "Label: 1, Embedding: [-0.01417823 -0.02919047 -0.00337841  0.00472716 -0.0082424 ]...\n",
      "Label: 1, Embedding: [ 0.01889     0.00910082  0.01400534 -0.01264187  0.00696296]...\n",
      "Label: 1, Embedding: [-0.00775869 -0.00614365  0.01038842 -0.02264309 -0.00263136]...\n",
      "Label: 0, Embedding: [-0.02075107 -0.00588193 -0.01075112 -0.01176386 -0.01101939]...\n",
      "Label: 0, Embedding: [-0.0192867  -0.00590961  0.02401181 -0.01951845 -0.01015191]...\n",
      "Label: 0, Embedding: [-0.01163044 -0.00418092  0.01447898 -0.01730126 -0.01920466]...\n",
      "Label: 0, Embedding: [-0.00315431  0.00221654 -0.01049252 -0.0111942  -0.0210375 ]...\n",
      "Label: 1, Embedding: [-0.00800406  0.01445015 -0.00120824 -0.03593711 -0.01412557]...\n",
      "Label: 1, Embedding: [-0.00985163 -0.00315927  0.01299435 -0.034484   -0.0189093 ]...\n",
      "Label: 1, Embedding: [-0.00922671 -0.02331247  0.00072894 -0.04411352  0.00504671]...\n",
      "Label: 1, Embedding: [-0.00480079 -0.01824106 -0.00374117 -0.01109675  0.00540211]...\n",
      "Label: 1, Embedding: [ 0.01208172  0.00406337  0.0136256  -0.00996627  0.01056411]...\n",
      "Label: 1, Embedding: [-0.01010336 -0.01193447 -0.00363643 -0.02385604  0.00501299]...\n",
      "Label: 0, Embedding: [-0.02157597 -0.01695636 -0.00728322 -0.01552776 -0.01231005]...\n",
      "Label: 0, Embedding: [-0.01324155 -0.01239105  0.00356553 -0.01200506 -0.01524348]...\n",
      "Label: 0, Embedding: [-0.02758204  0.00418443  0.02008259 -0.0196313  -0.02978542]...\n",
      "Label: 0, Embedding: [-0.01251636  0.00403387 -0.01538623 -0.00588022 -0.0199352 ]...\n",
      "Label: 1, Embedding: [-0.02621454  0.00425578 -0.00184678 -0.02845029 -0.01381983]...\n",
      "Label: 1, Embedding: [-0.00949281 -0.00409917 -0.0021738  -0.0244904  -0.03161655]...\n"
     ]
    }
   ],
   "source": [
    "# Print embeddings and labels for inspection\n",
    "print(\"Embeddings and Labels:\")\n",
    "for emb, label in zip(embeddings, augmented_labels):\n",
    "    print(f\"Label: {label}, Embedding: {emb[:5]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
