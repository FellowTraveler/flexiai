{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /home/razvansavin/Proiecte/FlexiAI/flexiai/examples/Code examples\n",
      "Changed Directory to: /home/razvansavin/Proiecte/FlexiAI/flexiai\n",
      "Project root added to sys.path\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Check current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Current Directory: {current_dir}\")\n",
    "\n",
    "# Change to your project root directory\n",
    "project_root = '/home/razvansavin/Proiecte/FlexiAI/flexiai'\n",
    "os.chdir(project_root)\n",
    "print(f\"Changed Directory to: {os.getcwd()}\")\n",
    "\n",
    "# Add project root directory to sys.path\n",
    "sys.path.append(project_root)\n",
    "print(f\"Project root added to sys.path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 00:35:09,407 - INFO - task_manager.py - Initializing TaskManager\n",
      "2024-08-18 00:35:09,408 - INFO - function_mapping.py - User directory detected: /home/razvansavin/Proiecte/FlexiAI/flexiai/user_flexiai_rag\n",
      "2024-08-18 00:35:09,409 - INFO - run_manager.py - Initialized RunManager with personal functions: []\n",
      "2024-08-18 00:35:09,410 - INFO - run_manager.py - Initialized RunManager with assistant functions: []\n",
      "2024-08-18 00:35:09,413 - INFO - function_mapping.py - Attempting to import module: user_helpers\n",
      "2024-08-18 00:35:09,416 - INFO - function_mapping.py - Attempting to import module: user_task_manager\n",
      "2024-08-18 00:35:09,419 - INFO - function_mapping.py - Attempting to import module: user_function_mapping\n",
      "2024-08-18 00:35:09,421 - INFO - user_function_mapping.py - Registering user tasks\n",
      "2024-08-18 00:35:09,422 - INFO - function_mapping.py - Successfully registered user functions from user_function_mapping\n",
      "2024-08-18 00:35:09,423 - INFO - task_manager.py - User-defined tasks loaded successfully\n",
      "2024-08-18 00:35:09,424 - INFO - task_manager.py - Assistant function mapping: {'communicate_with_assistant': <bound method UserTaskManager.continue_conversation_with_assistant of <user_flexiai_rag.user_task_manager.UserTaskManager object at 0x7fef1b1522d0>>}\n",
      "2024-08-18 00:35:09,425 - INFO - task_manager.py - Personal function mapping: {'save_processed_content': <bound method UserTaskManager.save_processed_content of <user_flexiai_rag.user_task_manager.UserTaskManager object at 0x7fef1b1522d0>>, 'load_processed_content': <bound method UserTaskManager.load_processed_content of <user_flexiai_rag.user_task_manager.UserTaskManager object at 0x7fef1b1522d0>>, 'initialize_agent': <bound method UserTaskManager.initialize_agent of <user_flexiai_rag.user_task_manager.UserTaskManager object at 0x7fef1b1522d0>>, 'search_youtube': <bound method UserTaskManager.search_youtube of <user_flexiai_rag.user_task_manager.UserTaskManager object at 0x7fef1b1522d0>>}\n",
      "2024-08-18 00:35:09,426 - INFO - run_manager.py - Initialized RunManager with personal functions: ['save_processed_content', 'load_processed_content', 'initialize_agent', 'search_youtube']\n",
      "2024-08-18 00:35:09,428 - INFO - run_manager.py - Initialized RunManager with assistant functions: ['communicate_with_assistant']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/razvansavin/Proiecte/FlexiAI/flexiai\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from openai import NotFoundError, OpenAIError\n",
    "from flexiai.core.flexiai_client import FlexiAI\n",
    "from flexiai.config.logging_config import setup_logging\n",
    "\n",
    "# Initialize logging and FlexiAI client\n",
    "setup_logging(\n",
    "    root_level=logging.INFO, \n",
    "    file_level=logging.INFO, \n",
    "    console_level=logging.INFO, \n",
    "    enable_file_logging=True, \n",
    "    enable_console_logging=True\n",
    ")\n",
    "flexiai = FlexiAI()\n",
    "\n",
    "client = flexiai.client\n",
    "logger = flexiai.logger\n",
    "assistant_manager = flexiai.assistant_manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 00:35:11,925 - INFO - 115677037.py - Creating a new assistant...\n",
      "2024-08-18 00:35:12,345 - INFO - _client.py - HTTP Request: POST https://api.openai.com/v1/assistants \"HTTP/1.1 200 OK\"\n",
      "2024-08-18 00:35:12,352 - INFO - assistant_manager.py - Assistant created with ID: asst_iNOtB4j8yQXRNR364FlBnPPb\n",
      "2024-08-18 00:35:12,353 - INFO - 115677037.py - New assistant created with ID: asst_iNOtB4j8yQXRNR364FlBnPPb\n",
      "2024-08-18 00:35:12,354 - INFO - 115677037.py - Creating a new thread...\n",
      "2024-08-18 00:35:12,355 - INFO - thread_manager.py - Creating a new thread\n",
      "2024-08-18 00:35:12,595 - INFO - _client.py - HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "2024-08-18 00:35:12,605 - INFO - thread_manager.py - Created thread with ID: thread_0cdyDQFpT1xAp20sPBZdomcs\n",
      "2024-08-18 00:35:12,606 - INFO - 115677037.py - New thread created with ID: thread_0cdyDQFpT1xAp20sPBZdomcs\n",
      "2024-08-18 00:35:12,607 - INFO - 115677037.py - Attaching assistant asst_iNOtB4j8yQXRNR364FlBnPPb to the new thread...\n",
      "2024-08-18 00:35:12,609 - INFO - assistant_manager.py - Attaching assistant ID: asst_iNOtB4j8yQXRNR364FlBnPPb to thread ID: thread_0cdyDQFpT1xAp20sPBZdomcs\n",
      "2024-08-18 00:35:13,225 - INFO - _client.py - HTTP Request: POST https://api.openai.com/v1/threads/thread_0cdyDQFpT1xAp20sPBZdomcs/runs \"HTTP/1.1 200 OK\"\n",
      "2024-08-18 00:35:13,228 - INFO - assistant_manager.py - Attached assistant ID: asst_iNOtB4j8yQXRNR364FlBnPPb to thread ID: thread_0cdyDQFpT1xAp20sPBZdomcs\n",
      "2024-08-18 00:35:13,229 - INFO - 115677037.py - Assistant attached to the thread. Run details: Run(id='run_GlfTjceuzT89AmmHChSqCZgK', assistant_id='asst_iNOtB4j8yQXRNR364FlBnPPb', cancelled_at=None, completed_at=None, created_at=1723930513, expires_at=1723931113, failed_at=None, incomplete_details=None, instructions='You are a helpful assistant who loves using emoji ðŸ˜Š', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o-mini', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=None, status='queued', thread_id='thread_0cdyDQFpT1xAp20sPBZdomcs', tool_choice='auto', tools=[], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=0.7, top_p=0.9, tool_resources={})\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a new assistant, then attach it to a new thread\n",
    "try:\n",
    "    logger.info(\"Creating a new assistant...\")\n",
    "    assistant = assistant_manager.handle_assistant_for_thread(\n",
    "        instructions=\"You are a helpful assistant who loves using emoji ðŸ˜Š\",\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        action=\"create\"\n",
    "    )\n",
    "    logger.info(f\"New assistant created with ID: {assistant.id}\")\n",
    "\n",
    "    logger.info(\"Creating a new thread...\")\n",
    "    thread = flexiai.thread_manager.create_thread()\n",
    "    thread_id = thread.id\n",
    "    logger.info(f\"New thread created with ID: {thread_id}\")\n",
    "\n",
    "    logger.info(f\"Attaching assistant {assistant.id} to the new thread...\")\n",
    "    new_run = assistant_manager.handle_assistant_for_thread(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=assistant.id,\n",
    "        action=\"attach\"\n",
    "    )\n",
    "    logger.info(f\"Assistant attached to the thread. Run details: {new_run}\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to create and attach a new assistant: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 00:35:16,218 - INFO - 3666001964.py - Creating a new thread for an existing assistant...\n",
      "2024-08-18 00:35:16,221 - INFO - thread_manager.py - Creating a new thread\n",
      "2024-08-18 00:35:16,454 - INFO - _client.py - HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "2024-08-18 00:35:16,456 - INFO - thread_manager.py - Created thread with ID: thread_hIiJZK43FwOCppRqVDdDMi8n\n",
      "2024-08-18 00:35:16,457 - INFO - 3666001964.py - New thread created with ID: thread_hIiJZK43FwOCppRqVDdDMi8n\n",
      "2024-08-18 00:35:16,458 - INFO - 3666001964.py - Attaching assistant ID asst_tA3PCaGYOdJISeR4Hbko1s5R to the new thread...\n",
      "2024-08-18 00:35:16,459 - INFO - assistant_manager.py - Attaching assistant ID: asst_tA3PCaGYOdJISeR4Hbko1s5R to thread ID: thread_hIiJZK43FwOCppRqVDdDMi8n\n",
      "2024-08-18 00:35:16,932 - INFO - _client.py - HTTP Request: POST https://api.openai.com/v1/threads/thread_hIiJZK43FwOCppRqVDdDMi8n/runs \"HTTP/1.1 200 OK\"\n",
      "2024-08-18 00:35:16,933 - INFO - assistant_manager.py - Attached assistant ID: asst_tA3PCaGYOdJISeR4Hbko1s5R to thread ID: thread_hIiJZK43FwOCppRqVDdDMi8n\n",
      "2024-08-18 00:35:16,934 - INFO - 3666001964.py - Assistant attached to the new thread. Run details: Run(id='run_mpm9ehBrNQo5C81SqGvsLrOO', assistant_id='asst_tA3PCaGYOdJISeR4Hbko1s5R', cancelled_at=None, completed_at=None, created_at=1723930517, expires_at=1723931117, failed_at=None, incomplete_details=None, instructions='You are an even more helpful assistant who uses advanced language and emoji ðŸ¤–ðŸ˜Š', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o-mini', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=None, status='queued', thread_id='thread_hIiJZK43FwOCppRqVDdDMi8n', tool_choice='auto', tools=[], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=0.6, top_p=0.8, tool_resources={})\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Attach an existing assistant to a new thread\n",
    "try:\n",
    "    logger.info(\"Creating a new thread for an existing assistant...\")\n",
    "    thread = flexiai.thread_manager.create_thread()\n",
    "    thread_id = thread.id\n",
    "    logger.info(f\"New thread created with ID: {thread_id}\")\n",
    "\n",
    "    assistant_id = 'asst_tA3PCaGYOdJISeR4Hbko1s5R'  # Example existing assistant ID\n",
    "    logger.info(f\"Attaching assistant ID {assistant_id} to the new thread...\")\n",
    "    run = assistant_manager.handle_assistant_for_thread(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=assistant_id,\n",
    "        action=\"attach\"\n",
    "    )\n",
    "    logger.info(f\"Assistant attached to the new thread. Run details: {run}\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to attach an existing assistant to the new thread: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 00:35:40,827 - INFO - 2163126814.py - Updating assistant with ID: asst_iNOtB4j8yQXRNR364FlBnPPb\n",
      "2024-08-18 00:35:41,142 - INFO - _client.py - HTTP Request: GET https://api.openai.com/v1/assistants/asst_iNOtB4j8yQXRNR364FlBnPPb \"HTTP/1.1 200 OK\"\n",
      "2024-08-18 00:35:41,144 - INFO - assistant_manager.py - Assistant retrieved: Assistant(id='asst_iNOtB4j8yQXRNR364FlBnPPb', created_at=1723930512, description=None, instructions='You are a helpful assistant who loves using emoji ðŸ˜Š', metadata={}, model='gpt-4o-mini', name=None, object='assistant', tools=[], response_format='auto', temperature=0.7, tool_resources=ToolResources(code_interpreter=None, file_search=None), top_p=0.9)\n",
      "2024-08-18 00:35:41,643 - INFO - _client.py - HTTP Request: POST https://api.openai.com/v1/assistants/asst_iNOtB4j8yQXRNR364FlBnPPb \"HTTP/1.1 200 OK\"\n",
      "2024-08-18 00:35:41,645 - INFO - assistant_manager.py - Assistant updated with ID: asst_iNOtB4j8yQXRNR364FlBnPPb\n",
      "2024-08-18 00:35:41,646 - INFO - 2163126814.py - Assistant updated successfully.\n",
      "2024-08-18 00:35:41,646 - INFO - 2163126814.py - Creating a new thread for the updated assistant...\n",
      "2024-08-18 00:35:41,648 - INFO - thread_manager.py - Creating a new thread\n",
      "2024-08-18 00:35:41,870 - INFO - _client.py - HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "2024-08-18 00:35:41,872 - INFO - thread_manager.py - Created thread with ID: thread_4nrzNku5iiPf5D126nzbXXc1\n",
      "2024-08-18 00:35:41,872 - INFO - 2163126814.py - New thread created with ID: thread_4nrzNku5iiPf5D126nzbXXc1\n",
      "2024-08-18 00:35:41,873 - INFO - assistant_manager.py - Attaching assistant ID: asst_iNOtB4j8yQXRNR364FlBnPPb to thread ID: thread_4nrzNku5iiPf5D126nzbXXc1\n",
      "2024-08-18 00:35:42,404 - INFO - _client.py - HTTP Request: POST https://api.openai.com/v1/threads/thread_4nrzNku5iiPf5D126nzbXXc1/runs \"HTTP/1.1 200 OK\"\n",
      "2024-08-18 00:35:42,405 - INFO - assistant_manager.py - Attached assistant ID: asst_iNOtB4j8yQXRNR364FlBnPPb to thread ID: thread_4nrzNku5iiPf5D126nzbXXc1\n",
      "2024-08-18 00:35:42,406 - INFO - 2163126814.py - Updated assistant attached to the new thread. Run details: Run(id='run_PWdWUnnte1nkzoknE5fjHkP2', assistant_id='asst_iNOtB4j8yQXRNR364FlBnPPb', cancelled_at=None, completed_at=None, created_at=1723930542, expires_at=1723931142, failed_at=None, incomplete_details=None, instructions='You are assistant Mario ðŸ¤–.', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o-mini', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=None, status='queued', thread_id='thread_4nrzNku5iiPf5D126nzbXXc1', tool_choice='auto', tools=[], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=0.6, top_p=0.8, tool_resources={})\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Update an existing assistant, then attach it to a new thread\n",
    "try:\n",
    "    assistant_id = 'asst_iNOtB4j8yQXRNR364FlBnPPb'  # Example existing assistant ID\n",
    "    logger.info(f\"Updating assistant with ID: {assistant_id}\")\n",
    "\n",
    "    # Retrieve the assistant to get the current name\n",
    "    assistant_details = assistant_manager.handle_assistant_for_thread(\n",
    "        thread_id=None,\n",
    "        assistant_id=assistant_id,\n",
    "        action=\"retrieve\"\n",
    "    )\n",
    "    current_name = assistant_details.name or \"Mario Assistant\"  # Use a default if name is None\n",
    "\n",
    "    # Update the assistant with the current name\n",
    "    assistant_manager.handle_assistant_for_thread(\n",
    "        thread_id=None,  # No thread required for update\n",
    "        instructions=\"You are assistant Mario ðŸ¤–.\",\n",
    "        model=\"gpt-4o-mini\",\n",
    "        name=current_name,  # Update assistant name \n",
    "        temperature=0.6,\n",
    "        top_p=0.8,\n",
    "        assistant_id=assistant_id,\n",
    "        action=\"update\"\n",
    "    )\n",
    "    logger.info(f\"Assistant updated successfully.\")\n",
    "\n",
    "    # Optionally attach the updated assistant to a new thread\n",
    "    logger.info(\"Creating a new thread for the updated assistant...\")\n",
    "    thread = flexiai.thread_manager.create_thread()\n",
    "    thread_id = thread.id\n",
    "    logger.info(f\"New thread created with ID: {thread_id}\")\n",
    "\n",
    "    run = assistant_manager.handle_assistant_for_thread(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=assistant_id,\n",
    "        action=\"attach\"\n",
    "    )\n",
    "    logger.info(f\"Updated assistant attached to the new thread. Run details: {run}\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to update and attach the assistant: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 00:35:54,930 - INFO - 1108908160.py - Retrieving assistant with ID: asst_iNOtB4j8yQXRNR364FlBnPPb\n",
      "2024-08-18 00:35:55,235 - INFO - _client.py - HTTP Request: GET https://api.openai.com/v1/assistants/asst_iNOtB4j8yQXRNR364FlBnPPb \"HTTP/1.1 200 OK\"\n",
      "2024-08-18 00:35:55,236 - INFO - assistant_manager.py - Assistant retrieved: Assistant(id='asst_iNOtB4j8yQXRNR364FlBnPPb', created_at=1723930512, description=None, instructions='You are assistant Mario ðŸ¤–.', metadata={}, model='gpt-4o-mini', name='Mario Assistant', object='assistant', tools=[], response_format='auto', temperature=0.6, tool_resources=ToolResources(code_interpreter=None, file_search=None), top_p=0.8)\n",
      "2024-08-18 00:35:55,237 - INFO - 1108908160.py - Assistant details: Assistant(id='asst_iNOtB4j8yQXRNR364FlBnPPb', created_at=1723930512, description=None, instructions='You are assistant Mario ðŸ¤–.', metadata={}, model='gpt-4o-mini', name='Mario Assistant', object='assistant', tools=[], response_format='auto', temperature=0.6, tool_resources=ToolResources(code_interpreter=None, file_search=None), top_p=0.8)\n",
      "2024-08-18 00:35:55,238 - INFO - 1108908160.py - Creating a new thread for the retrieved assistant...\n",
      "2024-08-18 00:35:55,239 - INFO - thread_manager.py - Creating a new thread\n",
      "2024-08-18 00:35:55,492 - INFO - _client.py - HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "2024-08-18 00:35:55,497 - INFO - thread_manager.py - Created thread with ID: thread_4V2z1oCCsfa4UAQ6zR0EKIy6\n",
      "2024-08-18 00:35:55,499 - INFO - 1108908160.py - New thread created with ID: thread_4V2z1oCCsfa4UAQ6zR0EKIy6\n",
      "2024-08-18 00:35:55,500 - INFO - assistant_manager.py - Attaching assistant ID: asst_iNOtB4j8yQXRNR364FlBnPPb to thread ID: thread_4V2z1oCCsfa4UAQ6zR0EKIy6\n",
      "2024-08-18 00:35:56,075 - INFO - _client.py - HTTP Request: POST https://api.openai.com/v1/threads/thread_4V2z1oCCsfa4UAQ6zR0EKIy6/runs \"HTTP/1.1 200 OK\"\n",
      "2024-08-18 00:35:56,078 - INFO - assistant_manager.py - Attached assistant ID: asst_iNOtB4j8yQXRNR364FlBnPPb to thread ID: thread_4V2z1oCCsfa4UAQ6zR0EKIy6\n",
      "2024-08-18 00:35:56,079 - INFO - 1108908160.py - Retrieved assistant attached to the new thread. Run details: Run(id='run_d9FJIaDkC50rVSuHm3J7z8t1', assistant_id='asst_iNOtB4j8yQXRNR364FlBnPPb', cancelled_at=None, completed_at=None, created_at=1723930555, expires_at=1723931155, failed_at=None, incomplete_details=None, instructions='You are assistant Mario ðŸ¤–.', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4o-mini', object='thread.run', parallel_tool_calls=True, required_action=None, response_format='auto', started_at=None, status='queued', thread_id='thread_4V2z1oCCsfa4UAQ6zR0EKIy6', tool_choice='auto', tools=[], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=0.6, top_p=0.8, tool_resources={})\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Retrieve an existing assistant, then attach it to a new thread\n",
    "try:\n",
    "    assistant_id = 'asst_iNOtB4j8yQXRNR364FlBnPPb'  # Example existing assistant ID\n",
    "    logger.info(f\"Retrieving assistant with ID: {assistant_id}\")\n",
    "\n",
    "    assistant_details = assistant_manager.handle_assistant_for_thread(\n",
    "        thread_id=None,  # No thread required for retrieval\n",
    "        assistant_id=assistant_id,\n",
    "        action=\"retrieve\"\n",
    "    )\n",
    "    logger.info(f\"Assistant details: {assistant_details}\")\n",
    "\n",
    "    # Optionally attach the retrieved assistant to a new thread\n",
    "    logger.info(\"Creating a new thread for the retrieved assistant...\")\n",
    "    thread = flexiai.thread_manager.create_thread()\n",
    "    thread_id = thread.id\n",
    "    logger.info(f\"New thread created with ID: {thread_id}\")\n",
    "\n",
    "    run = assistant_manager.handle_assistant_for_thread(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=assistant_id,\n",
    "        action=\"attach\"\n",
    "    )\n",
    "    logger.info(f\"Retrieved assistant attached to the new thread. Run details: {run}\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to retrieve and attach the assistant: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 00:36:09,397 - INFO - 2844870114.py - Retrieving settings for assistant ID: asst_iNOtB4j8yQXRNR364FlBnPPb\n",
      "2024-08-18 00:36:09,673 - INFO - _client.py - HTTP Request: GET https://api.openai.com/v1/assistants/asst_iNOtB4j8yQXRNR364FlBnPPb \"HTTP/1.1 200 OK\"\n",
      "2024-08-18 00:36:09,674 - INFO - assistant_manager.py - Assistant retrieved: Assistant(id='asst_iNOtB4j8yQXRNR364FlBnPPb', created_at=1723930512, description=None, instructions='You are assistant Mario ðŸ¤–.', metadata={}, model='gpt-4o-mini', name='Mario Assistant', object='assistant', tools=[], response_format='auto', temperature=0.6, tool_resources=ToolResources(code_interpreter=None, file_search=None), top_p=0.8)\n",
      "2024-08-18 00:36:09,675 - INFO - assistant_manager.py - Assistant settings retrieved for ID: asst_iNOtB4j8yQXRNR364FlBnPPb\n",
      "2024-08-18 00:36:09,676 - INFO - 2844870114.py - Assistant settings retrieved: {'id': 'asst_iNOtB4j8yQXRNR364FlBnPPb', 'name': 'Mario Assistant', 'instructions': 'You are assistant Mario ðŸ¤–.', 'model': 'gpt-4o-mini', 'temperature': 0.6, 'top_p': 0.8, 'tools': [], 'tool_resources': ToolResources(code_interpreter=None, file_search=None), 'response_format': 'auto', 'metadata': {}}\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Retrieve assistant settings and print them\n",
    "try:\n",
    "    assistant_id = 'asst_iNOtB4j8yQXRNR364FlBnPPb'  # Example existing assistant ID\n",
    "    logger.info(f\"Retrieving settings for assistant ID: {assistant_id}\")\n",
    "\n",
    "    # Retrieve assistant settings using the new function\n",
    "    assistant_settings = assistant_manager.retrieve_assistant_settings(assistant_id)\n",
    "    \n",
    "    # Print the retrieved settings for evaluation\n",
    "    logger.info(f\"Assistant settings retrieved: {assistant_settings}\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to retrieve assistant settings: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 00:36:17,710 - INFO - 229382329.py - Deleting the assistant with ID: asst_iNOtB4j8yQXRNR364FlBnPPb\n",
      "2024-08-18 00:36:18,001 - INFO - _client.py - HTTP Request: DELETE https://api.openai.com/v1/assistants/asst_iNOtB4j8yQXRNR364FlBnPPb \"HTTP/1.1 200 OK\"\n",
      "2024-08-18 00:36:18,002 - INFO - assistant_manager.py - Assistant deleted: asst_iNOtB4j8yQXRNR364FlBnPPb\n",
      "2024-08-18 00:36:18,003 - INFO - 229382329.py - Assistant deleted successfully. Deletion response: AssistantDeleted(id='asst_iNOtB4j8yQXRNR364FlBnPPb', deleted=True, object='assistant.deleted')\n"
     ]
    }
   ],
   "source": [
    "assistant_id ='asst_iNOtB4j8yQXRNR364FlBnPPb'\n",
    "\n",
    "# Step 6: Delete the created assistant after testing\n",
    "try:\n",
    "    logger.info(f\"Deleting the assistant with ID: {assistant_id}\")\n",
    "    \n",
    "    # Delete the assistant using the assistant_manager\n",
    "    delete_response = assistant_manager.handle_assistant_for_thread(\n",
    "        thread_id=None,  # No thread is needed for deletion\n",
    "        assistant_id=assistant_id,\n",
    "        action=\"delete\"\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Assistant deleted successfully. Deletion response: {delete_response}\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to delete the assistant with ID: {assistant_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/razvansavin/Proiecte/FlexiAI/flexiai\n",
      "{   'id': 'asst_bxt62YG46C5wn4t5U1ESqJZf',\n",
      "    'instructions': 'Introduction\\n'\n",
      "                    '\\n'\n",
      "                    'You are Assistant Alpha, a generalist assistant designed '\n",
      "                    'to handle a wide range of user requests. One of your key '\n",
      "                    'functions is to perform YouTube searches on user request '\n",
      "                    \"using the 'search_youtube' function.\\n\"\n",
      "                    '\\n'\n",
      "                    'Workflow\\n'\n",
      "                    '\\n'\n",
      "                    'General Inquiries\\n'\n",
      "                    '\\n'\n",
      "                    'Handling General Inquiries: Address user queries, '\n",
      "                    'providing information, support, and resources as needed.\\n'\n",
      "                    '\\n'\n",
      "                    'Function-Specific Instructions\\n'\n",
      "                    '\\n'\n",
      "                    \"Function 'search_youtube':\\n\"\n",
      "                    '\\n'\n",
      "                    'Description: This function triggers a YouTube search in '\n",
      "                    'the default web browser using a specified search query. '\n",
      "                    'It constructs a URL with the encoded search terms and '\n",
      "                    'opens it directly in the browser.\\n'\n",
      "                    'Parameters:\\n'\n",
      "                    '\\n'\n",
      "                    \"    'query': A string representing the search terms to be \"\n",
      "                    'used in the YouTube search.\\n'\n",
      "                    '\\n'\n",
      "                    'Steps:\\n'\n",
      "                    '\\n'\n",
      "                    '    Receive the search query from the user.\\n'\n",
      "                    '    Construct the YouTube search URL using the provided '\n",
      "                    'query.\\n'\n",
      "                    '    Open the constructed URL in the default web browser.\\n'\n",
      "                    '\\n'\n",
      "                    'Confirmation: Ensure user confirmation before proceeding '\n",
      "                    'with the search.\\n'\n",
      "                    '\\n'\n",
      "                    \"Function 'save_processed_content':\\n\"\n",
      "                    '\\n'\n",
      "                    'Description: Saves the processed user content using the '\n",
      "                    \"'from_assistant_id' and 'to_assistant_id'. Use your \"\n",
      "                    \"assistant ID for the 'from_assistant_id' parameter and \"\n",
      "                    \"the target agent's assistant ID for the 'to_assistant_id' \"\n",
      "                    'parameter to save processed content for another agent.\\n'\n",
      "                    'Parameters:\\n'\n",
      "                    '\\n'\n",
      "                    \"    'from_assistant_id': The assistant identifier from \"\n",
      "                    'which the content originates. Use your assistant ID to '\n",
      "                    'fill this parameter when saving processed content.\\n'\n",
      "                    \"    'to_assistant_id': The assistant identifier to which \"\n",
      "                    'the content is directed. Fill this with the target '\n",
      "                    \"agent's assistant ID to store content for them.\\n\"\n",
      "                    \"    'processed_content': The processed content to store. \"\n",
      "                    'This is the actual data that needs to be saved.\\n'\n",
      "                    '\\n'\n",
      "                    'Steps:\\n'\n",
      "                    '\\n'\n",
      "                    \"    Receive the 'from_assistant_id', 'to_assistant_id', \"\n",
      "                    \"and 'processed_content' from the user.\\n\"\n",
      "                    '    Validate the input parameters to ensure they are not '\n",
      "                    'empty.\\n'\n",
      "                    '    Save the processed content using the provided '\n",
      "                    'parameters.\\n'\n",
      "                    '\\n'\n",
      "                    \"Function 'load_processed_content':\\n\"\n",
      "                    '\\n'\n",
      "                    'Description: Loads the stored processed user content '\n",
      "                    \"using the 'from_assistant_id' and 'to_assistant_id'. \"\n",
      "                    'Optionally retrieves content from all assistants if '\n",
      "                    \"'multiple_retrieval' is True. To retrieve all data sent \"\n",
      "                    'to your assistant ID from multiple agents, set '\n",
      "                    \"'multiple_retrieval' to True and use your assistant ID \"\n",
      "                    \"for the 'to_assistant_id' parameter. You can choose any \"\n",
      "                    \"assistant ID for the 'from_assistant_id' parameter in \"\n",
      "                    'this case.\\n'\n",
      "                    'Parameters:\\n'\n",
      "                    '\\n'\n",
      "                    \"    'from_assistant_id': The assistant identifier from \"\n",
      "                    'which the content originates. This should be the ID of '\n",
      "                    'the assistant whose content you want to retrieve. If '\n",
      "                    \"'multiple_retrieval' is True, you can use any assistant \"\n",
      "                    'ID.\\n'\n",
      "                    \"    'to_assistant_id': The assistant identifier to which \"\n",
      "                    'the content is directed. Use your assistant ID to fill '\n",
      "                    'this parameter to retrieve data sent to you.\\n'\n",
      "                    \"    'multiple_retrieval': Whether to retrieve content \"\n",
      "                    'from all sources, not just the specified '\n",
      "                    \"'to_assistant_id'. Set this parameter to True to retrieve \"\n",
      "                    'all data stored by multiple agents for you.\\n'\n",
      "                    '\\n'\n",
      "                    'Steps:\\n'\n",
      "                    '\\n'\n",
      "                    \"    Receive the 'from_assistant_id', 'to_assistant_id', \"\n",
      "                    \"and 'multiple_retrieval' parameters from the user.\\n\"\n",
      "                    '    Validate the input parameters to ensure they are not '\n",
      "                    'empty.\\n'\n",
      "                    '    Load the processed content using the provided '\n",
      "                    'parameters.\\n'\n",
      "                    '\\n'\n",
      "                    \"Function 'communicate_with_assistant':\\n\"\n",
      "                    '\\n'\n",
      "                    'Description: This function allows your assistant to '\n",
      "                    'communicate with another assistant using the specified '\n",
      "                    \"'assistant_id' and deliver the user content to the target \"\n",
      "                    'assistant.\\n'\n",
      "                    'Parameters:\\n'\n",
      "                    '\\n'\n",
      "                    \"    'assistant_id': The assistant identifier of the agent \"\n",
      "                    'you want to contact. This should be the ID of the target '\n",
      "                    'assistant.\\n'\n",
      "                    \"    'user_content': The content provided by the user that \"\n",
      "                    'needs to be delivered to the target assistant.\\n'\n",
      "                    '\\n'\n",
      "                    'Steps:\\n'\n",
      "                    '\\n'\n",
      "                    \"    Receive the 'assistant_id' and 'user_content' \"\n",
      "                    'parameters from the user.\\n'\n",
      "                    '    Validate the input parameters to ensure they are not '\n",
      "                    'empty.\\n'\n",
      "                    '    Deliver the user content to the specified assistant '\n",
      "                    'using the provided parameters.\\n'\n",
      "                    '    Ensure to pass the user content as \"User requested '\n",
      "                    'and complete details of the task..\" to make a '\n",
      "                    'professional request and mention that it includes the '\n",
      "                    'user request and all details.\\n'\n",
      "                    '    After delivering the content, automatically use the '\n",
      "                    \"'load_processed_content' function to retrieve the \"\n",
      "                    'response from the target assistant.\\n'\n",
      "                    '    Display the retrieved user processed content in a '\n",
      "                    'nice format to the user.\\n'\n",
      "                    '\\n'\n",
      "                    \"Function 'initialize_agent':\\n\"\n",
      "                    '\\n'\n",
      "                    'Description: Initialize an agent from the contact list '\n",
      "                    'using the specified assistant_id. The assistant is not '\n",
      "                    'allowed to use its own ID for this function.\\n'\n",
      "                    'Parameters:\\n'\n",
      "                    '\\n'\n",
      "                    \"    'assistant_id': The assistant identifier of the agent \"\n",
      "                    'you want to initiate. You cannot use your own assistant '\n",
      "                    'ID.\\n'\n",
      "                    '\\n'\n",
      "                    'Steps:\\n'\n",
      "                    '\\n'\n",
      "                    \"    Receive the agent's name from the user.\\n\"\n",
      "                    '    Check the contact list to find the assistant_id '\n",
      "                    \"corresponding to the requested agent's name.\\n\"\n",
      "                    \"    Validate that the 'assistant_id' is not your own ID.\\n\"\n",
      "                    '    Initialize the specified agent using the retrieved '\n",
      "                    \"'assistant_id'.\\n\"\n",
      "                    '\\n'\n",
      "                    'Additional Instructions\\n'\n",
      "                    '\\n'\n",
      "                    \"Using 'communicate_with_assistant' and \"\n",
      "                    \"'load_processed_content' Functions:\\n\"\n",
      "                    '\\n'\n",
      "                    '    When you want to fulfill a request from a user and '\n",
      "                    'need to call a specialized agent/assistant, use the '\n",
      "                    \"'communicate_with_assistant' function with the target \"\n",
      "                    \"assistant's ID and deliver the user task or information \"\n",
      "                    'without altering it.\\n'\n",
      "                    \"    Automatically use the 'load_processed_content' \"\n",
      "                    \"function to load the 'user_content' from that \"\n",
      "                    'agent/assistant immediately after using '\n",
      "                    \"'communicate_with_assistant'. Then deliver the user \"\n",
      "                    'content for processing and respond to the user with the '\n",
      "                    'retrieved data.\\n'\n",
      "                    '    Professional Request Handling: When calling any '\n",
      "                    'Agent, pass in user content as \"User requested and '\n",
      "                    'complete details of the task..\" to make a professional '\n",
      "                    'request and mention the user requested and all details.\\n'\n",
      "                    '    Formatting Retrieved Content: When you retrieve user '\n",
      "                    'processed content, display it in a clear and organized '\n",
      "                    'format, ensuring it is easy to read and understand.\\n'\n",
      "                    '\\n'\n",
      "                    'Important Instructions\\n'\n",
      "                    '\\n'\n",
      "                    '    Precision and Data Accuracy: Ensure precision and '\n",
      "                    'accuracy when filling all parameters for any function. '\n",
      "                    'Validate and double-check the data to maintain high '\n",
      "                    'quality and correctness. This is crucial for the proper '\n",
      "                    'execution of tasks and to ensure the integrity of the '\n",
      "                    'data being processed.\\n'\n",
      "                    '    Confirmation for Actions: Wait for user confirmation '\n",
      "                    'before initiating actions.\\n'\n",
      "                    '    Professionalism and Responsiveness: Maintain a '\n",
      "                    'professional tone and address queries promptly.\\n'\n",
      "                    '    Final Steps: Conclude interactions politely and '\n",
      "                    'encourage future contact.\\n'\n",
      "                    '\\n'\n",
      "                    'Contact List\\n'\n",
      "                    '\\n'\n",
      "                    \"    Your assistant ID: 'asst_bxt62YG46C5wn4t5U1ESqJZf'\\n\"\n",
      "                    '    Beta One assistant ID: '\n",
      "                    \"'asst_d3bHTEXEKWfBhTJtPEZN63aK'\\n\"\n",
      "                    '    Beta Two assistant ID: '\n",
      "                    \"'asst_mb9RLOyRa0jzQMQ6nc1KmL8Q'\\n\"\n",
      "                    \"    Gamma assistant ID: 'asst_RQehgdfCT83O1cB7uv8bdAqH'\\n\"\n",
      "                    '\\n'\n",
      "                    'General Guidelines\\n'\n",
      "                    '\\n'\n",
      "                    '    Professionalism: Maintain a professional tone.\\n'\n",
      "                    '    Responsiveness: Address queries promptly and '\n",
      "                    'accurately.\\n'\n",
      "                    '    Clarity: Provide clear and concise information.\\n'\n",
      "                    '    Adaptability: Handle a wide range of queries and '\n",
      "                    'requests.\\n'\n",
      "                    '\\n'\n",
      "                    'Conclusion\\n'\n",
      "                    '\\n'\n",
      "                    'Precision and data accuracy are paramount for the '\n",
      "                    'efficient and effective performance of tasks. Assistant '\n",
      "                    'Alpha must ensure that all parameters are filled with '\n",
      "                    'precision and accuracy, validate data meticulously, and '\n",
      "                    'maintain high standards of data integrity. By adhering to '\n",
      "                    'these guidelines, Alpha can provide reliable and '\n",
      "                    'satisfactory service, adapting to evolving user needs '\n",
      "                    'while ensuring data accuracy and precision at all times.',\n",
      "    'metadata': {},\n",
      "    'model': 'gpt-4o-mini',\n",
      "    'name': 'Alpha',\n",
      "    'response_format': 'auto',\n",
      "    'temperature': 0.5,\n",
      "    'tool_resources': ToolResources(code_interpreter=None, file_search=None),\n",
      "    'tools': [   FunctionTool(function=FunctionDefinition(name='save_processed_content', description=\"Saves the processed user content using the from_assistant_id and to_assistant_id. Use your assistant ID for the from_assistant_id parameter and the target agent's assistant ID for the to_assistant_id parameter to save processed content for another agent.\", parameters={'type': 'object', 'properties': {'from_assistant_id': {'type': 'string', 'description': 'The assistant identifier from which the content originates. Use your assistant ID to fill this parameter when saving processed content.', 'optional': False}, 'to_assistant_id': {'type': 'string', 'description': \"The assistant identifier to which the content is directed. Fill this with the target agent's assistant ID to store content for them.\", 'optional': False}, 'processed_content': {'type': 'string', 'description': 'The processed content to store. This is the actual data that needs to be saved.', 'optional': False}}, 'required': ['from_assistant_id', 'to_assistant_id', 'processed_content']}, strict=False), type='function'),\n",
      "                 FunctionTool(function=FunctionDefinition(name='load_processed_content', description='Loads the stored processed user content using the from_assistant_id and to_assistant_id. To retrieve all data sent to your assistant ID from multiple agents, set multiple_retrieval to True and use your assistant ID for the to_assistant_id parameter. You can choose any assistant ID for the from_assistant_id parameter in this case.', parameters={'type': 'object', 'properties': {'from_assistant_id': {'type': 'string', 'description': 'The assistant identifier from which the content originates. This should be the ID of the assistant whose content you want to retrieve. If multiple_retrieval is True, you can use any assistant ID.', 'optional': False}, 'to_assistant_id': {'type': 'string', 'description': 'The assistant identifier to which the content is directed. Use your assistant ID to fill this parameter to retrieve data sent to you.', 'optional': False}, 'multiple_retrieval': {'type': 'boolean', 'description': 'Set this parameter to True to retrieve all data stored by multiple agents for you. This will gather content from all from_assistant_ids directed to your to_assistant_id.', 'optional': False}}, 'required': ['from_assistant_id', 'to_assistant_id', 'multiple_retrieval']}, strict=False), type='function'),\n",
      "                 FunctionTool(function=FunctionDefinition(name='communicate_with_assistant', description='This function allows your assistant to communicate with another assistant using the specified assistant ID and deliver the user content to the target assistant.', parameters={'type': 'object', 'properties': {'assistant_id': {'type': 'string', 'description': 'The assistant identifier of the agent you want to contact. This should be the ID of the target assistant.', 'optional': False}, 'user_content': {'type': 'string', 'description': 'The content provided by the user that needs to be delivered to the target assistant.', 'optional': False}}, 'required': ['assistant_id', 'user_content']}, strict=False), type='function'),\n",
      "                 FunctionTool(function=FunctionDefinition(name='initialize_agent', description='Initialize an agent from the contact list using the specified assistant_id. The assistant is not allowed to use its own ID for this function.', parameters={'type': 'object', 'properties': {'assistant_id': {'type': 'string', 'description': 'The assistant identifier of the agent you want to initiate. You cannot use your own assistant ID.', 'optional': False}}, 'required': ['assistant_id']}, strict=False), type='function'),\n",
      "                 FunctionTool(function=FunctionDefinition(name='search_youtube', description='This function triggers a YouTube search in the default web browser using a specified search query. It constructs a URL with the encoded search terms and opens it directly in the browser.', parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'A string representing the search terms to be used in the YouTube search.', 'optional': False}}, 'required': ['query']}, strict=False), type='function')],\n",
      "    'top_p': 0.8}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import logging\n",
    "from openai import NotFoundError, OpenAIError\n",
    "from flexiai.core.flexiai_client import FlexiAI\n",
    "from flexiai.config.logging_config import setup_logging\n",
    "\n",
    "# Initialize logging and FlexiAI client\n",
    "setup_logging(\n",
    "    root_level=logging.ERROR, \n",
    "    file_level=logging.ERROR, \n",
    "    console_level=logging.ERROR, \n",
    "    enable_file_logging=True, \n",
    "    enable_console_logging=True\n",
    ")\n",
    "flexiai = FlexiAI()\n",
    "\n",
    "client = flexiai.client\n",
    "logger = flexiai.logger\n",
    "assistant_manager = flexiai.assistant_manager\n",
    "\n",
    "# Step 5: Retrieve assistant settings and print them\n",
    "try:\n",
    "    assistant_id = 'asst_bxt62YG46C5wn4t5U1ESqJZf'  # Example existing assistant ID\n",
    "    logger.info(f\"Retrieving settings for assistant ID: {assistant_id}\")\n",
    "\n",
    "    # Retrieve assistant settings using the new function\n",
    "    assistant_settings = assistant_manager.retrieve_assistant_settings(assistant_id)\n",
    "    \n",
    "    # Pretty print the retrieved settings for evaluation\n",
    "    logger.info(\"Assistant settings retrieved:\")\n",
    "    pprint.pprint(assistant_settings, indent=4)\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to retrieve assistant settings: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda_flexiai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
